{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Had issues installing pyreadstat so used magic command in notebook instead\n",
    "# %pip install pyreadstat"
   ],
   "id": "e4d2f7b2de23c373",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:19:31.342244Z",
     "start_time": "2025-05-01T15:19:30.197259Z"
    }
   },
   "source": [
    "import glob\n",
    "import pyreadstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:19:31.348564Z",
     "start_time": "2025-05-01T15:19:31.344473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Establish path to data folder\n",
    "DATA_DIR = Path('/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/dsp/data')\n",
    "\n",
    "#todo make cross-platform safe, or just add your own absolute path to the data folder "
   ],
   "id": "859e858140ec1c4a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tracking data\n",
    "\n",
    "## List of available tracking data\n",
    "\n",
    "Determine available tracking data per date, school, and class by subfolder name.\n",
    "\n",
    "⚠️ Currently only 2023 tracking data has been loaded since we do not have the survey responses to 2022 data.  "
   ],
   "id": "3a760b6a32c759d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:19:34.366985Z",
     "start_time": "2025-05-01T15:19:34.109418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'tracking-data-all'\n",
    "path = DATA_DIR / '02_interim' / f\"{filename}.csv\"\n",
    "\n",
    "summary_filename = 'tracking-data-summary'\n",
    "summary_path = DATA_DIR / '02_interim' / f\"{summary_filename}.csv\"\n",
    "\n",
    "if path.exists() and summary_path.exists():\n",
    "    print(f'Found {path}')\n",
    "    tracking_data = pd.read_csv(path).astype(str)\n",
    "    tracking_data['date'] = pd.to_datetime(tracking_data['date'])\n",
    "    \n",
    "    print(f'Found {summary_path}')\n",
    "    tracking_summary = pd.read_csv(summary_path).astype(str)\n",
    "    tracking_summary['date'] = pd.to_datetime(tracking_summary['date'])    \n",
    "else:\n",
    "    # Get 2023 school/class info from tracking data subfolder names\n",
    "    folder = DATA_DIR / '01_tracking' / '2023'\n",
    "    subfolders = [f.name for f in folder.iterdir() if f.is_dir()]\n",
    "    \n",
    "    # Initialize list to store all tracking data entries\n",
    "    all_data = []\n",
    "    \n",
    "    # Process each subfolder\n",
    "    for subfolder in subfolders:\n",
    "        date, school_num = subfolder.split('_s')\n",
    "        school_num, class_num = school_num.split('_c')\n",
    "        \n",
    "        # Get the full path to the subfolder\n",
    "        subfolder_path = folder / subfolder\n",
    "        \n",
    "        # Find all CSV files in the subfolder\n",
    "        csv_files = list(subfolder_path.glob('*.csv'))\n",
    "        \n",
    "        if csv_files:\n",
    "            # Process each CSV file in the subfolder\n",
    "            for csv_file in csv_files:\n",
    "                file_name = csv_file.name\n",
    "                \n",
    "                # Extract tracklab_id from filename by splitting on '] ' and taking the part after\n",
    "                if '] ' in file_name:\n",
    "                    tracklab_id = file_name.split('] ', 1)[1]\n",
    "                    # Remove .csv extension if present\n",
    "                    tracklab_id = tracklab_id.replace('.csv', '')\n",
    "                else:\n",
    "                    # Handle case where the expected delimiter isn't found\n",
    "                    tracklab_id = file_name.replace('.csv', '')\n",
    "                \n",
    "                # Add entry for this specific CSV file\n",
    "                all_data.append([date, school_num, class_num, tracklab_id])\n",
    "        else:\n",
    "            # If no CSV files found, still add the folder info without tracklab_id\n",
    "            all_data.append([date, school_num, class_num, None])\n",
    "    \n",
    "    # Create df with date, school, class, and tracklab_id\n",
    "    tracking_data = pd.DataFrame(all_data, columns=['date', 'school', 'class', 'tracklab_id'])\n",
    "    tracking_data = tracking_data.astype(str)\n",
    "    tracking_data['date'] = pd.to_datetime(tracking_data['date'], format='%Y_%m_%d')\n",
    "    \n",
    "    # Create summary df of unique date, school, and class combinations\n",
    "    tracking_summary= tracking_data[['date', 'school', 'class']].drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Save dfs as csv\n",
    "    summary_filename = 'tracking-data-summary'\n",
    "    summary_path = DATA_DIR / '02_interim' / f\"{summary_filename}.csv\"\n",
    "    summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tracking_summary.to_csv(summary_path, index=False)\n",
    "    print(\"Summary data saved to\", summary_path)\n",
    "    \n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tracking_data.to_csv(path, index=False)\n",
    "    print(\"All data saved to\", path)\n",
    "    \n",
    "    display(tracking_data)\n",
    "\n",
    "tracking_data.groupby(['date', 'school', 'class'])['tracklab_id'].nunique()"
   ],
   "id": "1c66ec8fd92936dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found /Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/dsp/data/02_interim/tracking-data-all.csv\n",
      "Found /Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/dsp/data/02_interim/tracking-data-summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date        school  class\n",
       "2023-04-11  42      102      16\n",
       "2023-05-11  43      103      30\n",
       "2023-05-23  46      107      20\n",
       "2023-05-24  47      108      15\n",
       "2023-05-31  1       104      22\n",
       "2023-06-08  45      105      22\n",
       "2023-06-09  45      106      16\n",
       "Name: tracklab_id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load TrackLabID keyfiles",
   "id": "dfbf158ba9a6f435"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:19:40.325471Z",
     "start_time": "2025-05-01T15:19:40.243227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'keyfile_tracklab_id'\n",
    "path = DATA_DIR / '02_interim' / f\"{filename}.csv\"\n",
    "\n",
    "if path.exists():\n",
    "    # Load formatted keyfile\n",
    "    print(f'Found {path}')\n",
    "    keyfile_tagID = pd.read_csv(path).astype(str)\n",
    "    display(keyfile_tagID)\n",
    "else:\n",
    "    # Load and format raw keyfile + save \n",
    "    path_raw = DATA_DIR / 'keyfiles' / 'Keyfile_csv.csv'\n",
    "    keyfile_tagID = pd.read_csv(path_raw, delimiter=';')\n",
    "    \n",
    "    keyfile_tagID = keyfile_tagID.astype(str)\n",
    "    keyfile_tagID = keyfile_tagID.rename(columns={'Tagnumber': 'tagnumber', 'TrackLabID': 'tracklab_id'})\n",
    "    \n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    keyfile_tagID.to_csv(path, index=False)\n",
    "    print(\"Data saved to\", path)"
   ],
   "id": "ba2b2b1fd9ee4e11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found /Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/dsp/data/02_interim/keyfile_tracklab_id.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   tagnumber     tracklab_id subject_id\n",
       "0          1  0x24025F48A3E6        nan\n",
       "1          2  0x24025F48A133        nan\n",
       "2          3  0x24025F44F8D7        nan\n",
       "3          4  0x24046130B076        nan\n",
       "4          5  0x24046131F437        nan\n",
       "..       ...             ...        ...\n",
       "65       131             nan        nan\n",
       "66       132             nan        nan\n",
       "67       133             nan        nan\n",
       "68       134             nan        nan\n",
       "69       135             nan        nan\n",
       "\n",
       "[70 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagnumber</th>\n",
       "      <th>tracklab_id</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0x24025F48A3E6</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0x24025F48A133</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0x24046130B076</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0x24046131F437</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>131</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>132</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>133</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>134</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>135</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Keyfiles",
   "id": "3101912dfad31d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:22:29.078549Z",
     "start_time": "2025-05-01T15:22:28.293947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = DATA_DIR / 'keyfiles'\n",
    "# file_path = folder.glob('*.xlsx')\n",
    "\n",
    "keyfiles = pd.DataFrame()\n",
    "\n",
    "for file in folder.glob('*.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(file, engine='openpyxl')\n",
    "        df['source'] = file.stem\n",
    "        keyfiles = pd.concat([keyfiles, df], ignore_index=True)\n",
    "        print(f'Loaded: {file.name}')\n",
    "    except Exception as e:\n",
    "        print(f'Could not read {file.name}: {e}')"
   ],
   "id": "21e3efe198cfc75f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: keyfile school 1 class 104.xlsx\n",
      "Loaded: keyfile school 41 class 100.xlsx\n",
      "Loaded: keyfile school 41 class 101.xlsx\n",
      "Loaded: keyfile school 42 class 102.xlsx\n",
      "Loaded: keyfile school 43 class 103.xlsx\n",
      "Loaded: keyfile school 45 class 105.xlsx\n",
      "Could not read ~$keyfile school 43 class 103.xlsx: File is not a zip file\n",
      "Loaded: keyfile school 46 class 107.xlsx\n",
      "Loaded: keyfile school 45 class 106.xlsx\n",
      "Loaded: keyfile school 47 class 108.xlsx\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:22:29.959513Z",
     "start_time": "2025-05-01T15:22:29.953605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert all entries to string\n",
    "keyfiles = keyfiles.apply(lambda x: x.apply(lambda y: str(int(y)) if pd.notna(y) and isinstance(y, (float, int)) else y))"
   ],
   "id": "a85cda5362e281b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Keyfiles **do not** share the same structure. Columns containing tag numbers are called tagnummer, tagnummer , tagnr, etc. Teachers are not entered according to an ID number but mostly denoted as 'leerkracht'. \n",
    "\n",
    "I'm merging the columns containing tag numbers into one column and assigning school and class numbers to techers, incl. ID number '9999'. "
   ],
   "id": "31931f0e5ed50096"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:22:32.801688Z",
     "start_time": "2025-05-01T15:22:32.797124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new column 'tagnumber' that combines all the tag number columns\n",
    "keyfiles['tagnumber'] = keyfiles['tagnummer'].copy()\n",
    "\n",
    "# Inspect column names\n",
    "print(keyfiles.columns)"
   ],
   "id": "f62ce020c5b06084",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['school ID', 'klas ID', 'subject ID', 'id', 'voornaam', 'achternaam',\n",
      "       'consent', 'tagnummer ', 'sID_survey', 'ID_survey', 'source', 'tagnr.',\n",
      "       'comment', 'tagnr', 'trackingnnumer', 'Unnamed: 11', 'tagnummer',\n",
      "       'tagnumber'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:22:33.891689Z",
     "start_time": "2025-05-01T15:22:33.887161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of tag number columns\n",
    "tag_columns = ['tagnummer', 'tagnummer ', 'tagnr.', 'tagnr', 'trackingnnumer']\n",
    "\n",
    "# Fill NaN values in 'tagnumber' with values from other tag columns\n",
    "for col in tag_columns:\n",
    "    if col != 'tagnummer':  # Skip the first column as we already copied it\n",
    "        keyfiles['tagnumber'] = keyfiles['tagnumber'].fillna(keyfiles[col])\n",
    "\n",
    "keyfiles = keyfiles.drop(columns=tag_columns)"
   ],
   "id": "963ab45c1f018d5e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:22:38.395569Z",
     "start_time": "2025-05-01T15:22:38.391262Z"
    }
   },
   "cell_type": "code",
   "source": "keyfiles.columns",
   "id": "7ab10327ce437433",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school ID', 'klas ID', 'subject ID', 'id', 'voornaam', 'achternaam',\n",
       "       'consent', 'sID_survey', 'ID_survey', 'source', 'comment',\n",
       "       'Unnamed: 11', 'tagnumber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:23:40.928175Z",
     "start_time": "2025-05-01T15:23:40.915718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the list of all columns in the DataFrame\n",
    "all_columns = keyfiles.columns.tolist()\n",
    "\n",
    "# Find the indices of 'source' and 'tagnumber' columns\n",
    "source_index = all_columns.index('source')\n",
    "tagnumber_index = all_columns.index('tagnumber')\n",
    "\n",
    "columns_between = all_columns[source_index+1:tagnumber_index]\n",
    "\n",
    "# Stack their entries in one series\n",
    "fill_values = keyfiles[columns_between].stack().groupby(level=0).first()\n",
    "\n",
    "# Unify them in new column 'comment', then remove individual columns\n",
    "keyfiles['comments'] = np.nan\n",
    "keyfiles['comments'] = keyfiles['comments'].fillna(fill_values)\n",
    "keyfiles = keyfiles.drop(columns = columns_between)"
   ],
   "id": "138baeae9713efe7",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Clean tag numbers\n",
    "1. Remove rows where tag numbers are empty or not a number"
   ],
   "id": "f28b34a14bf15a5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:21.505887Z",
     "start_time": "2025-05-01T14:41:21.502397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect values in tag number column\n",
    "# keyfiles['tagnumber'].unique()"
   ],
   "id": "1161d20b29a143aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9', '19', '14', '29', '28', '31', '33', '22', '5', '20', '2',\n",
       "       '30', '32', '18', '11', '1', '3', '34', '10', nan, '27', '25', '-',\n",
       "       '24', '15', '7', '17', '6', '21', '13', '26', '35',\n",
       "       'niet aanwezig, uit vragenlijst gehaald', 'niet aanwezig', '12',\n",
       "       'x '], dtype=object)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 326
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:21.508664Z",
     "start_time": "2025-05-01T14:41:21.506742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Keep only rows containing digits in tag number column\n",
    "# keyfiles = keyfiles[\n",
    "#     keyfiles['tagnumber'].notna() & \n",
    "#     keyfiles['tagnumber'].astype(str).str.isdigit()\n",
    "# ]\n",
    "# \n",
    "# # Inspect values in tag number again -> OK\n",
    "# keyfiles['tagnumber'].unique()"
   ],
   "id": "8404c542ef6aa49c",
   "outputs": [],
   "execution_count": 327
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:24:28.060756Z",
     "start_time": "2025-05-01T15:24:28.035070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename columns for alignment\n",
    "keyfiles = keyfiles.rename(columns={'school ID': 'school', 'klas ID': 'class', 'id': 'person_id', 'subject ID': 'subject_id'})\n",
    "\n",
    "# Add dates to keyfile by mapping\n",
    "keyfiles['date'] = np.nan\n",
    "date_map = tracking_data.set_index(['school', 'class'])['date'].to_dict()\n",
    "\n",
    "# # Update 'date' in keyfiles where keys match\n",
    "keyfiles['date'] = keyfiles.apply(\n",
    "    lambda row: date_map.get((row['school'], row['class']), row['date']),\n",
    "    axis=1\n",
    ")"
   ],
   "id": "1d593dd15bac10a4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:27:09.614504Z",
     "start_time": "2025-05-01T15:27:09.601776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename columns for alignment (fixed typo in variable name)\n",
    "# keyfiles = keyfiles.rename(columns={'tagnummer': 'tagnumber'})\n",
    "# keyfile_tagID = keyfile_tagID.rename(columns={'Tagnumber': 'tagnumber', 'TrackLabID': 'tracklabID'}).astype(str)\n",
    "\n",
    "# Create mapping dictionary - convert keys to same type as keyfiles['tagnumber']\n",
    "tracklab_id_map = keyfile_tagID.dropna(subset=['tagnumber']).set_index('tagnumber')['tracklab_id'].to_dict()\n",
    "\n",
    "# Map values more efficiently using map() instead of apply\n",
    "keyfiles['tracklab_id'] = keyfiles['tagnumber'].map(tracklab_id_map)"
   ],
   "id": "282ba5307e605f70",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:27:13.177980Z",
     "start_time": "2025-05-01T15:27:13.169584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# keyfiles = keyfiles.rename(columns={'subject ID': 'subject_id'})\n",
    "\n",
    "# Inspect consent entries\n",
    "print('Entries in CONSENT:')\n",
    "print(keyfiles['consent'].unique())\n",
    "\n",
    "# Get position of 'source' column\n",
    "source_position = list(keyfiles.columns).index('source')\n",
    "\n",
    "# Identify columns before 'source'\n",
    "cols_before_source = keyfiles.columns[:source_position]\n",
    "\n",
    "# Check if any of these columns contain 'leerkracht'\n",
    "has_leerkracht = keyfiles[cols_before_source].apply(\n",
    "    lambda col: col.astype(str).str.contains('leerkracht', case=False, na=False)\n",
    ").any(axis=1)\n",
    "\n",
    "# Assign '9999' to 'subject_ID' where 'leerkracht' was found\n",
    "keyfiles.loc[has_leerkracht, 'subject_id'] = '9999'\n",
    "\n",
    "# Replace positive non-digit consent entries with '1'\n",
    "keyfiles['consent'] = keyfiles['consent'].replace(\n",
    "    {'ja': '1', 'leerkracht': '1'}\n",
    ")\n",
    "\n",
    "# Inspect consent entries\n",
    "print('Entries in CONSENT:')\n",
    "print(keyfiles['consent'].unique())"
   ],
   "id": "f8d67e6d3ea434d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries in CONSENT:\n",
      "['1' '4' '5' 'ja, geen tracking' nan 'Ja, geen tracking' '35'\n",
      " 'received oral permission from parent on day of data collection']\n",
      "Entries in CONSENT:\n",
      "['1' '4' '5' 'ja, geen tracking' nan 'Ja, geen tracking' '35'\n",
      " 'received oral permission from parent on day of data collection']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:27:18.333578Z",
     "start_time": "2025-05-01T15:27:18.330626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#todo find out why school 44 has been (inconsistently) renamed school 1, and how we should call it\n",
    "keyfiles['school'] = keyfiles['school'].astype(str)\n",
    "# keyfiles.loc[keyfiles['school']=='44', 'school'] = '1'"
   ],
   "id": "6013be43fdadca0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Teacher responses\n",
    "\n",
    "Teacher survey responses look like they were collected through an online form. Delivered raw as wide-format SPSS files. \n",
    "\n",
    "# IOP scores\n",
    "\n",
    "Confirmed with Nathalie that IOP responses were optional.\n",
    "If IOP response was given, variable name contains 'Q68' and student number. It's then followed by Q70 and Q71 with matching student number.\n",
    "\n",
    "School and class data has been added to each dataframe from source filename. This data is surely already present in the questionnaire, but I cannot decipher under which variable it's present. Hence, a workaround."
   ],
   "id": "2970f2f24aa8e85d"
  },
  {
   "cell_type": "code",
   "id": "4ab5c31f7f61c73f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:30:55.985032Z",
     "start_time": "2025-05-01T15:30:34.662817Z"
    }
   },
   "source": [
    "# Determine path to raw SPSS files\n",
    "folder = DATA_DIR / '01_survey' / 'teacher_raw_2023'\n",
    "\n",
    "# Initiate empty dict to store teacher questionnaire dfs\n",
    "tq_all = {}\n",
    "\n",
    "for file in folder.glob('*.sav'):\n",
    "    var_name = file.stem\n",
    "    df = pd.read_spss(file)\n",
    "    \n",
    "    # Add school/class as columns to each df from filename\n",
    "    school_num, class_num = var_name.split('_')[1:]\n",
    "    df['school'] = school_num\n",
    "    df['class'] = class_num\n",
    "    \n",
    "    # Store df in dict with filename as key\n",
    "    tq_all[var_name] = df\n",
    "    print(f'Loaded dataframe: {var_name}')\n",
    "    \n",
    "print(f'Total dataframes: {len(tq_all)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe: tq_49_113\n",
      "Loaded dataframe: tq_1_104\n",
      "Loaded dataframe: tq_41_100\n",
      "Loaded dataframe: tq_41_101\n",
      "Loaded dataframe: tq_42_102\n",
      "Loaded dataframe: tq_43_103\n",
      "Loaded dataframe: tq_45_105\n",
      "Loaded dataframe: tq_45_106\n",
      "Loaded dataframe: tq_46_107\n",
      "Loaded dataframe: tq_47_108\n",
      "Loaded dataframe: tq_49_110\n",
      "Loaded dataframe: tq_49_111\n",
      "Loaded dataframe: tq_49_112\n",
      "Total dataframes: 13\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T18:18:00.624700Z",
     "start_time": "2025-04-28T18:18:00.622502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uncomment to inspect example of available columns\n",
    "# print(tq_all['tq_1_104'].columns.tolist())"
   ],
   "id": "6e16680ba75f7215",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:30:58.267774Z",
     "start_time": "2025-05-01T15:30:57.991730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initiate empty dict to store relevant tq only\n",
    "tq_relevant = {}\n",
    "\n",
    "for df in tq_all:\n",
    "    school_num = str(tq_all[df]['school'].iloc[0])\n",
    "    class_num = str(tq_all[df]['class'].iloc[0])\n",
    "    \n",
    "    tq_match = tracking_data[\n",
    "        (tracking_data['school'] == school_num) &\n",
    "        (tracking_data['class'] == class_num)\n",
    "    ]\n",
    "    \n",
    "    if not tq_match.empty:\n",
    "        tq_relevant[df] = tq_all[df]\n",
    "        print(f\"Matching dataframe: {df}\")\n",
    "\n",
    "#todo concatenate AFTER the columns have been equalized\n",
    "# tq = pd.concat(tq_relevant, ignore_index=True)\n",
    "\n",
    "print(f\"Total matching: {len(tq_relevant)}\")"
   ],
   "id": "5036e2a2-5a5d-4e05-ab77-4a920b51d0ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching dataframe: tq_1_104\n",
      "Matching dataframe: tq_42_102\n",
      "Matching dataframe: tq_43_103\n",
      "Matching dataframe: tq_45_105\n",
      "Matching dataframe: tq_45_106\n",
      "Matching dataframe: tq_46_107\n",
      "Matching dataframe: tq_47_108\n",
      "Total matching: 7\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Based on reading the codebook and inspecting the answers in the raw files, I've determined the following:\n",
    "* Q30 = school\n",
    "* Q31 = class\n",
    "* Q32 = ?\n",
    "* Q27 = T_gender\n",
    "* Q28 = T_age\n",
    "* Q29 = T_dutch\n",
    "* Q30.0 = T_exp1\n",
    "* Q31.0 = T_exp2\n",
    "* Q32.0 = T_time_teaching\n",
    "* Q33 = T_class_comp"
   ],
   "id": "183e5b0052c27f11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:00.168082Z",
     "start_time": "2025-05-01T15:31:00.165175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uncomment to inspect dataset\n",
    "# tq_relevant['tq_1_104']"
   ],
   "id": "5a867e46efa2b343",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q68: \"In vergelijking met andere leerlingen bezoek ik [naam kind]\"\n",
    "\n",
    "Q68 responses: Minder vaak, Gemiddeld, Vaker\n",
    "\n",
    "IOP response Q68 is given per student. Variable name format is 'Q68_N', where N should match an entry in keyfiles['subject ID']. By matching the subject ID, Q68 can then be matched to the 4-digit 'ID' in the file containing student survey responses (once these have been fixed). For an initial analysis, the matching to the 'subject ID' and thus to tracking tag numbers should be enough. "
   ],
   "id": "99952d9c85525ef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:03.168819Z",
     "start_time": "2025-05-01T15:31:03.081393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Eliminating irrelevant columns in tq dataframes\n",
    "\n",
    "# Lists of relevant questions\n",
    "descriptives = ['Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33']\n",
    "iop_id = ['Q68']  # Add 'Q70', 'Q71' for detailed IOP responses\n",
    "\n",
    "tq_filtered = {}\n",
    "\n",
    "for key, df in tq_relevant.items():\n",
    "    # Create a mask for columns to keep\n",
    "    cols_to_keep = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Check if column matches any descriptive column\n",
    "        if any(q_id in col for q_id in descriptives):\n",
    "            cols_to_keep.append(col)\n",
    "        # Check if column contains any of the specified question IDs\n",
    "        elif any(q_id in col for q_id in iop_id):\n",
    "            cols_to_keep.append(col)\n",
    "    \n",
    "    # Create a new dataframe with only the columns to keep\n",
    "    tq_filtered[key] = df[cols_to_keep]"
   ],
   "id": "1dc976f988fae873",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load IOP Q68 values into keyfiles df",
   "id": "9d29b40f3a7c7719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:41.531253Z",
     "start_time": "2025-05-01T15:31:40.694054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new column 'iop' in keyfiles if it doesn't exist\n",
    "if 'iop' not in keyfiles.columns:\n",
    "    keyfiles['iop'] = None  # Initialize with None values\n",
    "\n",
    "# Iterate through each dataframe in the dictionary\n",
    "for df_name, df in tq_filtered.items():\n",
    "    # Make a copy of the dataframe to ensure we're working with a clean copy\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert columns Q30 and Q31 to string type using .loc to avoid the warning\n",
    "    df_copy.loc[:, 'Q30'] = df_copy['Q30'].astype(str)\n",
    "    df_copy.loc[:, 'Q31'] = df_copy['Q31'].astype(str)\n",
    "    \n",
    "    # Identify the Q68_N columns (those that start with 'Q68_')\n",
    "    q68_cols = [col for col in df_copy.columns if col.startswith('Q68_')]\n",
    "    \n",
    "    # Iterate through each row in the dataframe\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        school = row['Q30']\n",
    "        class_val = row['Q31']\n",
    "        \n",
    "        # Check each Q68_N column for matching subjects\n",
    "        for q68_col in q68_cols:\n",
    "            # Extract just the number part from Q68_N column name\n",
    "            subject_id = q68_col.split('_')[1]  # Extract the N from Q68_N\n",
    "            \n",
    "            # Get the value from this Q68_N cell\n",
    "            q68_value = row[q68_col]\n",
    "            \n",
    "            # Only proceed if the cell has a valid value\n",
    "            if pd.notna(q68_value) and str(q68_value) != \"0\" and str(q68_value) != \"\":\n",
    "                # Find matching rows in keyfiles where all three conditions are met\n",
    "                matching_rows = keyfiles[(keyfiles['school'] == school) & \n",
    "                                        (keyfiles['class'] == class_val) & \n",
    "                                        (keyfiles['sID_survey'] == subject_id)]\n",
    "                \n",
    "                # If matches found, update the 'iop' column with the actual value from Q68_N\n",
    "                if not matching_rows.empty:\n",
    "                    keyfiles.loc[matching_rows.index, 'iop'] = q68_value"
   ],
   "id": "dca09374e1bbb48a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TEMP: Export merged file\n",
    "\n",
    "File includes connection school & class -> subject_id -> tagnumber -> tracklab_id + iop"
   ],
   "id": "a1ce3dd738091b38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:44.366201Z",
     "start_time": "2025-05-01T15:31:44.362705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp = tracking_data.copy().astype(str)\n",
    "temp.loc[temp['school']=='1', 'school'] = '44'"
   ],
   "id": "89afbf7c6a44d510",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:45.925378Z",
     "start_time": "2025-05-01T15:31:45.916447Z"
    }
   },
   "cell_type": "code",
   "source": "temp[temp['school']=='44']",
   "id": "a5a57af10680d224",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date school class     tracklab_id\n",
       "101  2023-05-31     44   104  0x24025F44B7A5\n",
       "102  2023-05-31     44   104  0x24025F44DBFA\n",
       "103  2023-05-31     44   104  0x24025F44E6FB\n",
       "104  2023-05-31     44   104  0x24025F44ECCF\n",
       "105  2023-05-31     44   104  0x24025F44F682\n",
       "106  2023-05-31     44   104  0x24025F465724\n",
       "107  2023-05-31     44   104  0x240461308FB5\n",
       "108  2023-05-31     44   104  0x24046130B6FA\n",
       "109  2023-05-31     44   104  0x24046130B9B6\n",
       "110  2023-05-31     44   104  0x24046130BA41\n",
       "111  2023-05-31     44   104  0x24046130BB1E\n",
       "112  2023-05-31     44   104  0x24046130BDD0\n",
       "113  2023-05-31     44   104  0x24046130C8AB\n",
       "114  2023-05-31     44   104  0x24046130C90F\n",
       "115  2023-05-31     44   104  0x24046130CCF9\n",
       "116  2023-05-31     44   104  0x24046130C9C5\n",
       "117  2023-05-31     44   104  0x24046131EE8C\n",
       "118  2023-05-31     44   104  0x24046131EF0E\n",
       "119  2023-05-31     44   104  0x24046131F062\n",
       "120  2023-05-31     44   104  0x24046131F437\n",
       "121  2023-05-31     44   104  0x24046131F584\n",
       "122  2023-05-31     44   104           Tag 1\n",
       "123  2023-05-31     44   104  0x24025F44DBFA\n",
       "124  2023-05-31     44   104  0x24025F44E6FB\n",
       "125  2023-05-31     44   104  0x24025F44ECCF\n",
       "126  2023-05-31     44   104  0x24025F44F682\n",
       "127  2023-05-31     44   104  0x240461308FB5\n",
       "128  2023-05-31     44   104  0x24046130BA41\n",
       "129  2023-05-31     44   104  0x24046130BB1E\n",
       "130  2023-05-31     44   104  0x24046130C9C5\n",
       "131  2023-05-31     44   104  0x24046131EE8C\n",
       "132  2023-05-31     44   104  0x24046131F062\n",
       "133  2023-05-31     44   104  0x24046131F437\n",
       "134  2023-05-31     44   104  0x24046131F584\n",
       "135  2023-05-31     44   104           Tag 1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>tracklab_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44B7A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44DBFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44E6FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44ECCF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44F682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F465724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x240461308FB5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130B6FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130B9B6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130BA41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130BB1E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130BDD0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130C8AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130C90F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130CCF9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130C9C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131EE8C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131EF0E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>Tag 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44DBFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44E6FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44ECCF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24025F44F682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x240461308FB5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130BA41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130BB1E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046130C9C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131EE8C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>0x24046131F584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>Tag 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:47.741685Z",
     "start_time": "2025-05-01T15:31:47.722318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, let's find the missing tracklab_ids for each school-class combination\n",
    "missing_entries = []\n",
    "\n",
    "# Get unique school-class combinations from keyfiles\n",
    "school_class_combinations = keyfiles[['school', 'class']].drop_duplicates()\n",
    "\n",
    "# For each school-class combination\n",
    "for _, row in school_class_combinations.iterrows():\n",
    "    school = row['school']\n",
    "    class_val = row['class']\n",
    "    \n",
    "    # Get all tracklab_ids for this school-class in tracking_data\n",
    "    tracking_ids = temp[(temp['school'] == school) & \n",
    "                        (temp['class'] == class_val)]['tracklab_id'].unique()\n",
    "    \n",
    "    # Get all tracklab_ids for this school-class already in keyfiles\n",
    "    keyfiles_ids = keyfiles[(keyfiles['school'] == school) & \n",
    "                           (keyfiles['class'] == class_val)]['tracklab_id'].unique()\n",
    "    \n",
    "    # Find tracklab_ids in tracking_data but not in keyfiles\n",
    "    missing_ids = set(tracking_ids) - set(keyfiles_ids)\n",
    "    \n",
    "    # Create new rows for each missing tracklab_id\n",
    "    for missing_id in missing_ids:\n",
    "        # Create a new row with school, class, and tracklab_id\n",
    "        new_row = {\n",
    "            'school': school,\n",
    "            'class': class_val,\n",
    "            'tracklab_id': missing_id\n",
    "        }\n",
    "        missing_entries.append(new_row)\n",
    "\n",
    "# Create DataFrame from the missing entries\n",
    "if missing_entries:\n",
    "    missing_df = pd.DataFrame(missing_entries)\n",
    "    \n",
    "    # Append the missing entries to keyfiles\n",
    "    keyfiles = pd.concat([keyfiles, missing_df], ignore_index=True)\n",
    "    \n",
    "    print(f\"Added {len(missing_entries)} new rows to keyfiles for missing tracklab_ids\")\n",
    "else:\n",
    "    print(\"No missing tracklab_ids found\")\n",
    "\n",
    "# Display the updated keyfiles DataFrame\n",
    "keyfiles.sort_values(by=['school', 'class', 'tracklab_id'])[['school', 'class', 'tracklab_id']]"
   ],
   "id": "9a9f3b3e7834e21c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing tracklab_ids found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    school class     tracklab_id\n",
       "22      41   100  0x24025F449A89\n",
       "21      41   100  0x24025F44AD21\n",
       "28      41   100  0x24025F44DBFA\n",
       "33      41   100  0x24025F44E6FB\n",
       "35      41   100  0x24025F44ECCF\n",
       "..     ...   ...             ...\n",
       "141    nan   NaN             NaN\n",
       "163    nan   NaN             NaN\n",
       "185    nan   NaN             NaN\n",
       "206    nan   NaN             NaN\n",
       "207    nan   NaN             NaN\n",
       "\n",
       "[247 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>tracklab_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>0x24025F449A89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>0x24025F44AD21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>0x24025F44DBFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>0x24025F44E6FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>0x24025F44ECCF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:31:54.581237Z",
     "start_time": "2025-05-01T15:31:54.247959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# temp = tracking_data.copy().astype(str)\n",
    "# temp.loc[temp['school']=='1'] = '44'\n",
    "\n",
    "export = keyfiles.loc[keyfiles['school'].isin(temp['school'].unique())]\n",
    "\n",
    "filename = 'merged-data-WIP'\n",
    "today = pd.to_datetime('today').strftime('%Y-%m-%d_%H-%M')\n",
    "savepath = DATA_DIR / '02_interim' / f\"{filename}_{today}.xlsx\"\n",
    "export.to_excel(savepath, index=False, engine='openpyxl')"
   ],
   "id": "126ff69bd55519a0",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Student responses",
   "id": "f058e4332cbd03c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:26.070997Z",
     "start_time": "2025-05-01T14:41:23.778460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'TotalData_T1_all_cbs_ethnicity_gender'\n",
    "path = DATA_DIR / '01_survey' / f\"{filename}.xlsx\"\n",
    "\n",
    "students_raw = pd.read_excel(path)\n",
    "\n",
    "students = students_raw.copy()\n",
    "\n",
    "# Rename columns to match keyfiles\n",
    "students = students.rename(columns={'School_ID': 'school', 'Class_ID': 'class', 'sID': 'subject_id', 'ID': 'person_id'}).astype(str)"
   ],
   "id": "4c71a62cd06d4c03",
   "outputs": [],
   "execution_count": 332
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Turn all columns before 'age' to string.\n",
    "\n",
    "This is totally arbitrary typecasting; I just need select columns in this range to be string. "
   ],
   "id": "cf498ac211f9bae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:26.074792Z",
     "start_time": "2025-05-01T14:41:26.072526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Get position of 'age' column\n",
    "# age_position = list(students.columns).index('age')\n",
    "# \n",
    "# # Identify columns before 'age'\n",
    "# cols_before_age = students.columns[:age_position]\n",
    "# \n",
    "# # Typecast to string\n",
    "# students[cols_before_age] = students[cols_before_age].astype('str')"
   ],
   "id": "8189b2a6720021e0",
   "outputs": [],
   "execution_count": 333
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:26.744251Z",
     "start_time": "2025-05-01T14:41:26.741756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Create a set of valid (school, class) pairs from tracking_data\n",
    "# valid_pairs = set(zip(tracking_data['school'], tracking_data['class']))\n",
    "# \n",
    "# # Filter students DataFrame\n",
    "# students = students[\n",
    "#     students.apply(lambda row: (row['school'], row['class']) in valid_pairs, axis=1)\n",
    "# ]"
   ],
   "id": "76338f7e1f22828c",
   "outputs": [],
   "execution_count": 334
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:27.744850Z",
     "start_time": "2025-05-01T14:41:27.742388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(students_raw.shape)\n",
    "print(students.shape)"
   ],
   "id": "34ad1db4dfdc525c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 534)\n",
      "(310, 534)\n"
     ]
    }
   ],
   "execution_count": 335
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:28.184040Z",
     "start_time": "2025-05-01T14:41:28.178554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create list of SPARTS score columns\n",
    "st_rel = [col for col in students_raw.columns if col.startswith('st_rel')]\n",
    "\n",
    "# Get index of 'gender_sr'\n",
    "gender_sr_idx = students.columns.get_loc('gender_sr')\n",
    "\n",
    "# Get all columns up to and including 'gender_sr'\n",
    "base_cols = students.columns[:gender_sr_idx+1]\n",
    "\n",
    "# Combine with st_rel columns\n",
    "students = students[list(base_cols) + st_rel]"
   ],
   "id": "cbfca7c79008efd2",
   "outputs": [],
   "execution_count": 336
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:35.757695Z",
     "start_time": "2025-05-01T14:41:35.730750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Discovered duplicate subject_id in raw student responses because my merge would not work, removing it now\n",
    "duplicate = students.loc[\n",
    "    (students.duplicated(['school', 'class', 'subject_id'], keep=False)) &\n",
    "    (students['consent'].astype(str)!='1')\n",
    "]\n",
    "\n",
    "duplicate"
   ],
   "id": "9283c9379de20cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    time school class cohort tracking condition_seating condition_game  \\\n",
       "114    1     41   100   2223        0                 0              0   \n",
       "128    1     41   100   2223        0                 0              0   \n",
       "238    1     45   105   2223        0                 0              0   \n",
       "\n",
       "    nPupils nAbsent dataPresent  ... st_rel4 st_rel5 st_rel6 st_rel7 st_rel8  \\\n",
       "114      25     nan           0  ...     nan     nan     nan     nan     nan   \n",
       "128      25     nan           0  ...     nan     nan     nan     nan     nan   \n",
       "238      22     nan           0  ...     nan     nan     nan     nan     nan   \n",
       "\n",
       "    st_rel9 st_rel10 st_rel11 st_rel13 st_rel12  \n",
       "114     nan      nan      nan      nan      nan  \n",
       "128     nan      nan      nan      nan      nan  \n",
       "238     nan      nan      nan      nan      nan  \n",
       "\n",
       "[3 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>cohort</th>\n",
       "      <th>tracking</th>\n",
       "      <th>condition_seating</th>\n",
       "      <th>condition_game</th>\n",
       "      <th>nPupils</th>\n",
       "      <th>nAbsent</th>\n",
       "      <th>dataPresent</th>\n",
       "      <th>...</th>\n",
       "      <th>st_rel4</th>\n",
       "      <th>st_rel5</th>\n",
       "      <th>st_rel6</th>\n",
       "      <th>st_rel7</th>\n",
       "      <th>st_rel8</th>\n",
       "      <th>st_rel9</th>\n",
       "      <th>st_rel10</th>\n",
       "      <th>st_rel11</th>\n",
       "      <th>st_rel13</th>\n",
       "      <th>st_rel12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>2223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>100</td>\n",
       "      <td>2223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>2223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 337
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:41:37.524398Z",
     "start_time": "2025-05-01T14:41:37.520818Z"
    }
   },
   "cell_type": "code",
   "source": "students = students.drop(duplicate.index)",
   "id": "9f0bd9caad416379",
   "outputs": [],
   "execution_count": 338
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T13:55:41.474205Z",
     "start_time": "2025-05-01T13:55:41.465928Z"
    }
   },
   "cell_type": "code",
   "source": "students_short = students[['school','class','tracking','nPupils','dataPresent','person_id','consent','subject_id','informed','assent']]",
   "id": "7b3932c340cfc60a",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Align student responses with keyfiles\n",
    "\n",
    "According to Nathalie, the order of the subject IDs ('subjectID') in the keyfiles are correct and can be matched to the student responses in the column 'sID'. The 4-digit person ID numbers ('id') were noted down incorrectly in the keyfiles. They can be copied from the student responses, according to 'sID'. -- MC, 01-05-2025   "
   ],
   "id": "163047d7969c4814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:33:59.785970Z",
     "start_time": "2025-05-01T14:33:59.769217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, ensure the columns are standardized for proper matching\n",
    "for col in ['school', 'class', 'subject_id']:\n",
    "    # Convert to string, strip whitespace, and make lowercase to ensure matching\n",
    "    keyfiles[col] = keyfiles[col].astype(str).str.strip().str.lower()\n",
    "    students[col] = students[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Create a composite key from the matching columns\n",
    "keyfiles['match_key'] = keyfiles['school'] + '|' + keyfiles['class'] + '|' + keyfiles['subject_id']\n",
    "students['match_key'] = students['school'] + '|' + students['class'] + '|' + students['subject_id']\n",
    "\n",
    "# Create a dictionary mapping from match_key to person_id\n",
    "person_id_map = students.set_index('match_key')['person_id'].to_dict()\n",
    "\n",
    "# Apply the mapping to keyfiles based on match_key\n",
    "keyfiles['person_id'] = keyfiles['match_key'].map(person_id_map)\n",
    "\n",
    "# Remove the temporary match_key column\n",
    "# keyfiles.drop('match_key', axis=1, inplace=True)\n",
    "# students.drop('match_key', axis=1, inplace=True)"
   ],
   "id": "59cefe65977bd5be",
   "outputs": [],
   "execution_count": 308
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "key",
   "id": "e8b05e34a26dc485"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:17:57.610506Z",
     "start_time": "2025-05-01T14:17:57.600912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change school 44 to 1 to match student response file\n",
    "keyfiles.loc[keyfiles['school']=='44', 'school'] = '1'"
   ],
   "id": "2f3d54d558d67990",
   "outputs": [],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:29:52.392078Z",
     "start_time": "2025-05-01T14:29:52.379865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prep for merge: typecast cols as str just in case\n",
    "# # Convert relevant columns to string in both DataFrames\n",
    "for col in ['school', 'class', 'subject_id', 'person_id']:\n",
    "    keyfiles.loc[:, col] = keyfiles[col].astype(str).str.strip()\n",
    "    students.loc[:, col] = students[col].astype(str).str.strip()\n",
    "    \n",
    "# merge_cols = ['school', 'class', 'subject_id', 'person_id']\n",
    "# keyfiles[merge_cols] = keyfiles[merge_cols].astype('str')\n",
    "# students[merge_cols] = students[merge_cols].astype('str')"
   ],
   "id": "7fdec865d0473973",
   "outputs": [],
   "execution_count": 290
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:29:54.014288Z",
     "start_time": "2025-05-01T14:29:54.007959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Merge keyfiles and student response file\n",
    "matched = keyfiles.merge(\n",
    "    students[['school', 'class', 'subject_id', 'person_id']],\n",
    "    on=['school', 'class', 'subject_id'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# Overwrite keyfiles['person_id'] with matches and assign NaN if no match\n",
    "# keyfiles['person_id'] = matched['person_id_new']"
   ],
   "id": "75e7523ff5382623",
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:34:18.023042Z",
     "start_time": "2025-05-01T14:34:18.012599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp = keyfiles[['school','class','subject_id','person_id', 'consent']]\n",
    "temp\n",
    "# temp[temp['person_id_new'].isna()]\n",
    "# temp.loc[temp['person_id']!=temp['person_id_new']]"
   ],
   "id": "f18e2a2dc61d9ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    school class subject_id person_id  \\\n",
       "0       47   108          1      2285   \n",
       "1       47   108          2      2286   \n",
       "2       47   108          3      2287   \n",
       "3       47   108          4      2288   \n",
       "4       47   108          5      2289   \n",
       "..     ...   ...        ...       ...   \n",
       "203     46   107         16      2278   \n",
       "204     46   107         17      2279   \n",
       "205     46   107         18      2280   \n",
       "206     46   107         19      2281   \n",
       "207     46   107         20      2283   \n",
       "\n",
       "                                               consent  \n",
       "0                                                    1  \n",
       "1                                                    1  \n",
       "2                                                    1  \n",
       "3                                                    1  \n",
       "4                                                    1  \n",
       "..                                                 ...  \n",
       "203                                                  1  \n",
       "204                                                  1  \n",
       "205                                                  1  \n",
       "206                                                  4  \n",
       "207  received oral permission from parent on day of...  \n",
       "\n",
       "[208 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>consent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>2286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>2287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>2288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "      <td>2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>17</td>\n",
       "      <td>2279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>19</td>\n",
       "      <td>2281</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>2283</td>\n",
       "      <td>received oral permission from parent on day of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 310
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:34:58.638597Z",
     "start_time": "2025-05-01T14:34:58.594467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Debug information to check matching problems\n",
    "def debug_matching():\n",
    "    \"\"\"Function to help debug matching issues\"\"\"\n",
    "    # Check where matches should happen but don't\n",
    "    keyfiles_sample = keyfiles.head(10)\n",
    "    print(\"Sample keyfiles data:\")\n",
    "    print(keyfiles_sample[['school', 'class', 'subject_id', 'person_id']])\n",
    "    \n",
    "    # For each row in sample, check if it should have matched\n",
    "    for idx, row in keyfiles_sample.iterrows():\n",
    "        match_key = f\"{row['school']}|{row['class']}|{row['subject_id']}\"\n",
    "        matches = students_short[\n",
    "            (students_short['school'] == row['school']) & \n",
    "            (students_short['class'] == row['class']) & \n",
    "            (students_short['subject_id'] == row['subject_id'])\n",
    "        ]\n",
    "        print(f\"\\nChecking row {idx}, match_key: {match_key}\")\n",
    "        print(f\"Found {len(matches)} matching rows in students_short\")\n",
    "        if len(matches) > 0:\n",
    "            print(\"Matching student data:\")\n",
    "            print(matches[['school', 'class', 'subject_id', 'person_id']])\n",
    "\n",
    "# Uncomment to run the debug function\n",
    "debug_matching()"
   ],
   "id": "5cb550f22a2c93c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keyfiles data:\n",
      "  school class subject_id person_id\n",
      "0     47   108          1      2285\n",
      "1     47   108          2      2286\n",
      "2     47   108          3      2287\n",
      "3     47   108          4      2288\n",
      "4     47   108          5      2289\n",
      "5     47   108          6      2290\n",
      "6     47   108          7      2291\n",
      "7     47   108          8      2292\n",
      "8     47   108          9      2293\n",
      "9     47   108         10      2294\n",
      "\n",
      "Checking row 0, match_key: 47|108|1\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "291     47   108          1      2285\n",
      "\n",
      "Checking row 1, match_key: 47|108|2\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "292     47   108          2      2286\n",
      "\n",
      "Checking row 2, match_key: 47|108|3\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "293     47   108          3      2287\n",
      "\n",
      "Checking row 3, match_key: 47|108|4\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "294     47   108          4      2288\n",
      "\n",
      "Checking row 4, match_key: 47|108|5\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "295     47   108          5      2289\n",
      "\n",
      "Checking row 5, match_key: 47|108|6\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "296     47   108          6      2290\n",
      "\n",
      "Checking row 6, match_key: 47|108|7\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "297     47   108          7      2291\n",
      "\n",
      "Checking row 7, match_key: 47|108|8\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "298     47   108          8      2292\n",
      "\n",
      "Checking row 8, match_key: 47|108|9\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "299     47   108          9      2293\n",
      "\n",
      "Checking row 9, match_key: 47|108|10\n",
      "Found 1 matching rows in students_short\n",
      "Matching student data:\n",
      "    school class subject_id person_id\n",
      "300     47   108         10      2294\n"
     ]
    }
   ],
   "execution_count": 311
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:39:31.197791Z",
     "start_time": "2025-05-01T14:39:31.066739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# First reset the person_id column in keyfiles (if it already exists)\n",
    "if 'person_id' in keyfiles.columns:\n",
    "    keyfiles['person_id'] = np.nan\n",
    "\n",
    "# Perform the merge\n",
    "merged = keyfiles.merge(\n",
    "    students[['school', 'class', 'subject_id', 'person_id']],\n",
    "    on=['school', 'class', 'subject_id'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Only use person_id values from the matches\n",
    "keyfiles['person_id'] = np.where(\n",
    "    merged['_merge'] == 'both',\n",
    "    merged['person_id'],\n",
    "    np.nan\n",
    ")\n"
   ],
   "id": "f7b177d5f0766635",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'person_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/dsp/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._engine.get_loc(casted_key)\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'person_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[320]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m      6\u001B[39m merged = keyfiles.merge(\n\u001B[32m      7\u001B[39m     students[[\u001B[33m'\u001B[39m\u001B[33mschool\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mclass\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33msubject_id\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mperson_id\u001B[39m\u001B[33m'\u001B[39m]],\n\u001B[32m      8\u001B[39m     on=[\u001B[33m'\u001B[39m\u001B[33mschool\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mclass\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33msubject_id\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m      9\u001B[39m     how=\u001B[33m'\u001B[39m\u001B[33mleft\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     10\u001B[39m     indicator=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     11\u001B[39m )\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Only use person_id values from the matches\u001B[39;00m\n\u001B[32m     14\u001B[39m keyfiles[\u001B[33m'\u001B[39m\u001B[33mperson_id\u001B[39m\u001B[33m'\u001B[39m] = np.where(\n\u001B[32m     15\u001B[39m     merged[\u001B[33m'\u001B[39m\u001B[33m_merge\u001B[39m\u001B[33m'\u001B[39m] == \u001B[33m'\u001B[39m\u001B[33mboth\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m     merged[\u001B[33m'\u001B[39m\u001B[33mperson_id\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     17\u001B[39m     np.nan\n\u001B[32m     18\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/dsp/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28mself\u001B[39m.columns.get_loc(key)\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/dsp/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'person_id'"
     ]
    }
   ],
   "execution_count": 320
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:37:56.153121Z",
     "start_time": "2025-05-01T14:37:56.132543Z"
    }
   },
   "cell_type": "code",
   "source": "merged",
   "id": "129df68a3820e41b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    school class subject_id  person_id_x voornaam achternaam  \\\n",
       "0       47   108          1          NaN      NaN        NaN   \n",
       "1       47   108          2          NaN      NaN        NaN   \n",
       "2       47   108          3          NaN      NaN        NaN   \n",
       "3       47   108          4          NaN      NaN        NaN   \n",
       "4       47   108          5          NaN      NaN        NaN   \n",
       "..     ...   ...        ...          ...      ...        ...   \n",
       "205     46   107         16          NaN      NaN        NaN   \n",
       "206     46   107         17          NaN      NaN        NaN   \n",
       "207     46   107         18          NaN      NaN        NaN   \n",
       "208     46   107         19          NaN      NaN        NaN   \n",
       "209     46   107         20          NaN      NaN        NaN   \n",
       "\n",
       "                                               consent  \\\n",
       "0                                                    1   \n",
       "1                                                    1   \n",
       "2                                                    1   \n",
       "3                                                    1   \n",
       "4                                                    1   \n",
       "..                                                 ...   \n",
       "205                                                  1   \n",
       "206                                                  1   \n",
       "207                                                  1   \n",
       "208                                                  4   \n",
       "209  received oral permission from parent on day of...   \n",
       "\n",
       "                          source tagnumber  \\\n",
       "0    keyfile school 47 class 108         9   \n",
       "1    keyfile school 47 class 108        19   \n",
       "2    keyfile school 47 class 108        14   \n",
       "3    keyfile school 47 class 108        29   \n",
       "4    keyfile school 47 class 108        28   \n",
       "..                           ...       ...   \n",
       "205  keyfile school 46 class 107        25   \n",
       "206  keyfile school 46 class 107        17   \n",
       "207  keyfile school 46 class 107         5   \n",
       "208  keyfile school 46 class 107       NaN   \n",
       "209  keyfile school 46 class 107         9   \n",
       "\n",
       "                                               comment       date  \\\n",
       "0                                                  NaN 2023-05-24   \n",
       "1                                                  NaN 2023-05-24   \n",
       "2                                                  NaN 2023-05-24   \n",
       "3                                                  NaN 2023-05-24   \n",
       "4                                                  NaN 2023-05-24   \n",
       "..                                                 ...        ...   \n",
       "205                                                NaN 2023-05-23   \n",
       "206                                                NaN 2023-05-23   \n",
       "207                                                NaN 2023-05-23   \n",
       "208                                                NaN 2023-05-23   \n",
       "209  since student had no written consent, their na... 2023-05-23   \n",
       "\n",
       "        tracklab_id  match_key person_id_y _merge  \n",
       "0    0x24046130C8AB   47|108|1        2285   both  \n",
       "1    0x24025F44AD21   47|108|2        2286   both  \n",
       "2    0x24025F449A89   47|108|3        2287   both  \n",
       "3    0x24025F44CDE1   47|108|4        2288   both  \n",
       "4    0x24025F4603F8   47|108|5        2289   both  \n",
       "..              ...        ...         ...    ...  \n",
       "205  0x240461308FB5  46|107|16        2278   both  \n",
       "206  0x24046131F062  46|107|17        2279   both  \n",
       "207  0x24046131F437  46|107|18        2280   both  \n",
       "208             NaN  46|107|19        2281   both  \n",
       "209  0x24046130C8AB  46|107|20        2283   both  \n",
       "\n",
       "[210 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>person_id_x</th>\n",
       "      <th>voornaam</th>\n",
       "      <th>achternaam</th>\n",
       "      <th>consent</th>\n",
       "      <th>source</th>\n",
       "      <th>tagnumber</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>tracklab_id</th>\n",
       "      <th>match_key</th>\n",
       "      <th>person_id_y</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 47 class 108</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>0x24046130C8AB</td>\n",
       "      <td>47|108|1</td>\n",
       "      <td>2285</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 47 class 108</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>0x24025F44AD21</td>\n",
       "      <td>47|108|2</td>\n",
       "      <td>2286</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 47 class 108</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>0x24025F449A89</td>\n",
       "      <td>47|108|3</td>\n",
       "      <td>2287</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 47 class 108</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "      <td>47|108|4</td>\n",
       "      <td>2288</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 47 class 108</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>0x24025F4603F8</td>\n",
       "      <td>47|108|5</td>\n",
       "      <td>2289</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 46 class 107</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>0x240461308FB5</td>\n",
       "      <td>46|107|16</td>\n",
       "      <td>2278</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 46 class 107</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>0x24046131F062</td>\n",
       "      <td>46|107|17</td>\n",
       "      <td>2279</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>keyfile school 46 class 107</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>0x24046131F437</td>\n",
       "      <td>46|107|18</td>\n",
       "      <td>2280</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>keyfile school 46 class 107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46|107|19</td>\n",
       "      <td>2281</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>received oral permission from parent on day of...</td>\n",
       "      <td>keyfile school 46 class 107</td>\n",
       "      <td>9</td>\n",
       "      <td>since student had no written consent, their na...</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>0x24046130C8AB</td>\n",
       "      <td>46|107|20</td>\n",
       "      <td>2283</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 316
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T13:20:37.324990Z",
     "start_time": "2025-05-01T13:20:37.315685Z"
    }
   },
   "cell_type": "code",
   "source": "keyfiles[['school', 'class','subject_id', 'person_id']]",
   "id": "dd0fbbc4c0a87299",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    school class subject_id person_id\n",
       "0       47   108          1      2285\n",
       "1       47   108          2      2286\n",
       "2       47   108          3      2287\n",
       "3       47   108          4      2288\n",
       "4       47   108          5      2289\n",
       "..     ...   ...        ...       ...\n",
       "203     46   107         16      2277\n",
       "204     46   107         17      2278\n",
       "205     46   107         18      2279\n",
       "206     46   107         19      2280\n",
       "207     46   107         20      2281\n",
       "\n",
       "[208 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>17</td>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>19</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Last attempt at aligning before switching to manual",
   "id": "e49170ad1f8ee49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:45:08.830384Z",
     "start_time": "2025-05-01T14:45:08.812825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create deep copies of the dataframes to avoid modifying the originals\n",
    "keyfiles_copy = keyfiles.copy()\n",
    "students_copy = students.copy()\n",
    "\n",
    "# Function to thoroughly standardize data for matching\n",
    "def standardize_column(df, column):\n",
    "    \"\"\"Apply comprehensive cleaning to ensure matching works\"\"\"\n",
    "    if column in df.columns:\n",
    "        # Handle different data types appropriately\n",
    "        if df[column].dtype.kind in 'ifc':  # numeric columns\n",
    "            # Convert numeric to string without scientific notation\n",
    "            df[column] = df[column].apply(lambda x: str(int(x)) if pd.notnull(x) and float(x).is_integer() else \n",
    "                                          (str(x) if pd.notnull(x) else np.nan))\n",
    "        else:\n",
    "            # For string/object columns\n",
    "            df[column] = df[column].astype(str)\n",
    "        \n",
    "        # Apply thorough cleaning\n",
    "        df[column] = df[column].str.strip()\n",
    "        df[column] = df[column].str.lower()\n",
    "        # Remove any non-visible characters\n",
    "        df[column] = df[column].str.replace(r'\\s+', ' ', regex=True)\n",
    "        # Normalize unicode characters\n",
    "        import unicodedata\n",
    "        df[column] = df[column].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Apply standardization to both dataframes\n",
    "for col in ['school', 'class', 'subject_id']:\n",
    "    # keyfiles_copy = standardize_column(keyfiles_copy, col)\n",
    "    students_copy = standardize_column(students_copy, col)"
   ],
   "id": "ef005c154749239b",
   "outputs": [],
   "execution_count": 340
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:45:28.726085Z",
     "start_time": "2025-05-01T14:45:28.607610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Alternative explicit approach using direct comparison and assignment\n",
    "def direct_matching_approach(keyfiles_df, students_df):\n",
    "    \"\"\"Direct matching approach that ensures complete control over the matching process\"\"\"\n",
    "    # Make sure person_id column exists in keyfiles\n",
    "    if 'person_id' not in keyfiles_df.columns:\n",
    "        keyfiles_df['person_id'] = np.nan\n",
    "    \n",
    "    # Iterate through each row in keyfiles\n",
    "    for idx, keyfile_row in keyfiles_df.iterrows():\n",
    "        # Find matching rows in students_df\n",
    "        matches = students_df[\n",
    "            (students_df['school'] == keyfile_row['school']) & \n",
    "            (students_df['class'] == keyfile_row['class']) & \n",
    "            (students_df['subject_id'] == keyfile_row['subject_id'])\n",
    "        ]\n",
    "        \n",
    "        # If there's a match, use the person_id\n",
    "        if len(matches) > 0:\n",
    "            keyfiles_df.at[idx, 'person_id'] = matches.iloc[0]['person_id']\n",
    "    \n",
    "    return keyfiles_df\n",
    "\n",
    "# If the previous methods still don't work, try this direct approach\n",
    "direct_result = direct_matching_approach(keyfiles_copy, students_copy)\n",
    "# keyfiles['person_id'] = direct_result['person_id']"
   ],
   "id": "18e36fecbfed9b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da976cadd8b5202c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T14:46:09.969810Z",
     "start_time": "2025-05-01T14:46:09.944186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp = direct_result[['school','class','subject_id','person_id', 'consent']]\n",
    "temp"
   ],
   "id": "83ebfce6dca917b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    school class subject_id person_id  \\\n",
       "0       47   108          1      2285   \n",
       "1       47   108          2      2286   \n",
       "2       47   108          3      2287   \n",
       "3       47   108          4      2288   \n",
       "4       47   108          5      2289   \n",
       "..     ...   ...        ...       ...   \n",
       "203     46   107         16      2278   \n",
       "204     46   107         17      2279   \n",
       "205     46   107         18      2280   \n",
       "206     46   107         19      2281   \n",
       "207     46   107         20      2283   \n",
       "\n",
       "                                               consent  \n",
       "0                                                    1  \n",
       "1                                                    1  \n",
       "2                                                    1  \n",
       "3                                                    1  \n",
       "4                                                    1  \n",
       "..                                                 ...  \n",
       "203                                                  1  \n",
       "204                                                  1  \n",
       "205                                                  1  \n",
       "206                                                  4  \n",
       "207  received oral permission from parent on day of...  \n",
       "\n",
       "[208 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>class</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>consent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>2286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>2287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>2288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "      <td>2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>17</td>\n",
       "      <td>2279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>19</td>\n",
       "      <td>2281</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>20</td>\n",
       "      <td>2283</td>\n",
       "      <td>received oral permission from parent on day of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 342
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SPARTS scores\n",
    "\n",
    "Source:  https://doi.org/10.1111/bjep.12094\n",
    "\n",
    "Relevant variables named 'SPARTSN' (e.g. 'SPARTS1') in the codebook, but this name is not present in the data. Instead, variables named **'st_relN'** have been identified as SPARTS scores. As explained in the codebook, the questionnaire contained 13 items, but Q13 was not presented to all students. After filtering the dataset for relevant data only (i.e., responses of students whose tracking data we have available), only responses 1-12 were available anyway.  \n",
    "\n",
    "Q12 is not part of the original scale, but developed for this study.\n",
    "\n",
    "I cannot find a score sheet for this test that is not behind a paywall. The COTAN entry for the SPARTS lists a 25-item test instead of the 13-item test used. \n",
    "\n",
    "#todo ask Yvonne & Nathalie for scoring sheet "
   ],
   "id": "8c3e5183a77bfaed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
