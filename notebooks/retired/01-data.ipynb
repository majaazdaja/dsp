{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138973a8182f9bb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:49:37.663662Z",
     "start_time": "2025-04-25T08:49:36.924351Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import pyreadstat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eec7ae9fc66605",
   "metadata": {},
   "source": [
    "\n",
    "# Methods\n",
    "\n",
    "*I added an RQ and some hypotheses because we need a specific goal instead of just digging around in data. I didn't think about these much so please add to them and refine them.--MC, 11-04-2025*  \n",
    "\n",
    "**RQ:** How do explicit (IOP) and implicit (XYZ coordinates) measurement of teacher movement relate to student-teacher relationships (STRS, SPARTS)?\n",
    "\n",
    "**Hypothesis 1:** Higher IOP positively correlates with higher STRS and SPARTS.\n",
    "\n",
    "**Hypothesis 2:** Higher IOP positively correlates with closer proximity. \n",
    "* *But how are we going to define proximity? Maybe determine a range for how many times a day teacher approached student (also need to determine how long they need to stay next to the student to count as approaching), and how much time total the teacher spent close to student?--MC, 11-04-2025*\n",
    "\n",
    "1. **Import data**\n",
    "    1. Import tracking data\n",
    "        * Timestamps, XYZ coordinates, TagId\n",
    "    2. Import survey data\n",
    "        * Teachers: IOP, STRS\n",
    "        * Students: SPARS\n",
    "    3. Identify matching data\n",
    "        * School/classroom/TagID -> teacher <-> student\n",
    "2. **Pre-process data**\n",
    "    1. Tracking data\n",
    "        * Remove outliers\n",
    "        * Fill in missing timestamps: tracker goes to sleep mode, see VU paper for method\n",
    "        * Determine tracking start and end time\n",
    "        * Determine baseline distances (e.g. personal space, see VU paper again)\n",
    "    2. Survey data\n",
    "        * Calculate scores: check codebook for sources on correct computation\n",
    "        * Check for weird data (they're reliable scales so I guess it should be fine--MC, 11-04-2025) \n",
    "3. **Process data**\n",
    "    * Calculate Euclidean distances teacher-student\n",
    "    * Calculate how many times teacher approached student and vice versa\n",
    "        * *How exactly are we going to determine this?--MC, 11-04-2025*\n",
    "4. **Analysis** \n",
    "    * Regression analysis tracking data vs survey scores\n",
    "    * ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6171b534ffdd0",
   "metadata": {},
   "source": [
    "# Import data\n",
    "## Option 1: Load tracking data from single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load all movement CSV files into dataframes separated per day\n",
    "folder = '/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/Data export 7 klassen april-juni 23/11 april'\n",
    "\n",
    "file_path = glob.glob(folder + '/*.csv')\n",
    "\n",
    "dataframes = [pd.read_csv(file, sep=';') for file in file_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cee9feec4f6da",
   "metadata": {},
   "source": [
    "## Option 2: Load tracking data from all subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7adb6336f99c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing all 2023 notebooks\n",
    "folder = '/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/Data export 7 klassen april-juni 23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89737baa5e398b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T09:04:53.091671Z",
     "start_time": "2025-04-11T09:04:52.973701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found subfolders: ['31 mei', '8 juni', '9 juni', '11 april', '11 mei', '23 mei', '24 mei']\n"
     ]
    }
   ],
   "source": [
    "# Create list of subfolders\n",
    "subfolders = [f.name for f in os.scandir(folder) if f.is_dir()]\n",
    "\n",
    "# Verify detected subfolders\n",
    "print(f\"Found subfolders: {subfolders}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7292e11236e4d04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T09:07:20.773031Z",
     "start_time": "2025-04-11T09:05:10.604365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35 DataFrames into dfs_31_mei\n",
      "Loaded 43 DataFrames into dfs_8_juni\n",
      "Loaded 16 DataFrames into dfs_9_juni\n",
      "Loaded 16 DataFrames into dfs_11_april\n",
      "Loaded 30 DataFrames into dfs_11_mei\n",
      "Loaded 40 DataFrames into dfs_23_mei\n",
      "Loaded 15 DataFrames into dfs_24_mei\n"
     ]
    }
   ],
   "source": [
    "# Load CSV files in separate dataframes per subfolder\n",
    "for subfolder in subfolders:\n",
    "    # Create variable name (replacing spaces with underscores)\n",
    "    var_name = f\"dfs_{subfolder.replace(' ', '_').lower()}\"\n",
    "    \n",
    "    # Load CSV files from subfolder\n",
    "    csv_files = glob.glob(os.path.join(folder, subfolder, '*.csv'))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {subfolder}\")\n",
    "        continue\n",
    "    \n",
    "    dfs = [pd.read_csv(file, sep=';') for file in csv_files]\n",
    "    \n",
    "    # Store in global namespace\n",
    "    globals()[var_name] = dfs\n",
    "    print(f\"Loaded {len(dfs)} DataFrames into {var_name}\")\n",
    "\n",
    "# Now you can access them like:\n",
    "# dfs_subfolder1, dfs_subfolder2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505339932c5bb9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T09:19:11.512766Z",
     "start_time": "2025-04-11T09:19:09.586125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspecting files from April 11\n",
    "\n",
    "dfs_11_april = pd.concat(dfs_11_april)\n",
    "dfs_11_april['TimeStamp'] = pd.to_datetime(dfs_11_april['TimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f775bb009a97080c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T09:19:15.186393Z",
     "start_time": "2025-04-11T09:19:15.178584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>TagId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-11 09:17:34.580</td>\n",
       "      <td>1.107881</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.743003</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11 09:17:34.751</td>\n",
       "      <td>1.107881</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.515614</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-11 09:17:34.924</td>\n",
       "      <td>1.107881</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.400963</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-11 09:17:35.093</td>\n",
       "      <td>1.107881</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.353199</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-11 09:17:35.222</td>\n",
       "      <td>1.107881</td>\n",
       "      <td>0.706208</td>\n",
       "      <td>0.537513</td>\n",
       "      <td>0x24025F44CDE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843</th>\n",
       "      <td>2023-04-11 14:16:50.026</td>\n",
       "      <td>4.294939</td>\n",
       "      <td>4.364043</td>\n",
       "      <td>0.408307</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23844</th>\n",
       "      <td>2023-04-11 14:16:50.205</td>\n",
       "      <td>4.294939</td>\n",
       "      <td>4.364043</td>\n",
       "      <td>0.210187</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23845</th>\n",
       "      <td>2023-04-11 14:16:50.375</td>\n",
       "      <td>4.294939</td>\n",
       "      <td>4.364043</td>\n",
       "      <td>0.223637</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23846</th>\n",
       "      <td>2023-04-11 14:16:50.562</td>\n",
       "      <td>4.294939</td>\n",
       "      <td>4.364043</td>\n",
       "      <td>0.469377</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23847</th>\n",
       "      <td>2023-04-11 14:16:50.702</td>\n",
       "      <td>4.294939</td>\n",
       "      <td>4.364043</td>\n",
       "      <td>0.566619</td>\n",
       "      <td>0x24025F44F8D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672419 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TimeStamp         X         Y         Z           TagId\n",
       "0     2023-04-11 09:17:34.580  1.107881  0.706208  0.743003  0x24025F44CDE1\n",
       "1     2023-04-11 09:17:34.751  1.107881  0.706208  0.515614  0x24025F44CDE1\n",
       "2     2023-04-11 09:17:34.924  1.107881  0.706208  0.400963  0x24025F44CDE1\n",
       "3     2023-04-11 09:17:35.093  1.107881  0.706208  0.353199  0x24025F44CDE1\n",
       "4     2023-04-11 09:17:35.222  1.107881  0.706208  0.537513  0x24025F44CDE1\n",
       "...                       ...       ...       ...       ...             ...\n",
       "23843 2023-04-11 14:16:50.026  4.294939  4.364043  0.408307  0x24025F44F8D7\n",
       "23844 2023-04-11 14:16:50.205  4.294939  4.364043  0.210187  0x24025F44F8D7\n",
       "23845 2023-04-11 14:16:50.375  4.294939  4.364043  0.223637  0x24025F44F8D7\n",
       "23846 2023-04-11 14:16:50.562  4.294939  4.364043  0.469377  0x24025F44F8D7\n",
       "23847 2023-04-11 14:16:50.702  4.294939  4.364043  0.566619  0x24025F44F8D7\n",
       "\n",
       "[672419 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfs_11_april"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e193085e7f6082",
   "metadata": {},
   "source": [
    "## Establish available data\n",
    "\n",
    "Difficult to establish which data we do have and which data we don't because (1) no proper readme file was given and (2) naming conventions are inconsistent. I compared the folder and file names for the tracking data and established we seem to have the following available.\n",
    "\n",
    "**Warning: the days for 2022 dates are incorrect.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "934074986c93f182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T17:38:10.341611Z",
     "start_time": "2025-04-11T17:38:10.333653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Available data format = (YYYY-MM-DD, (school, class))\n",
    "\n",
    "available_data= [\n",
    "    ('2022-06-01', (31, 79)),\n",
    "    ('2022-06-01', (31, 80)),\n",
    "    ('2022-06-01', (31, 73)),\n",
    "    ('2022-06-01', (31, 74)),\n",
    "    ('2022-06-01', (31, 75)),\n",
    "    ('2023-06-08', (45, 105)),\n",
    "    ('2023-06-09', (45, 106)),\n",
    "    ('2023-04-11', (42, 102)),\n",
    "    ('2023-05-11', (43, 103)),\n",
    "    ('2023-05-23', (46, 107)),\n",
    "    ('2023-05-24', (47, 108)),\n",
    "    ('2023-05-31', (1, 104))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ced62f8b16fbe",
   "metadata": {},
   "source": [
    "Present in all student data file but no tracking data: (32, 73), (32, 74), (32, 75), (41, 100), (41, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186ad640f8662d1",
   "metadata": {},
   "source": [
    "## Load survey answers\n",
    "### Student data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7a0be996ed0cfab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T12:59:15.495834Z",
     "start_time": "2025-04-11T12:59:14.255730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Excel containing all student data\n",
    "students_raw = pd.read_excel('/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/TotalData_T1_all_cbs_ethnicity_gender.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0211f1198d83443",
   "metadata": {},
   "source": [
    "Because we only need student data pertaining to their ID values and SPARTS scores (vars st_relX), we create a separate dataframe containing only these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8853702131b9dd21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T12:59:17.646206Z",
     "start_time": "2025-04-11T12:59:17.636987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create list of SPARTS score columns\n",
    "st_rel = [col for col in students_raw.columns if col.startswith('st_rel')]\n",
    "\n",
    "# Batch-limit student data up to and incl. column 'gender_sr' and add SPARTS scores\n",
    "students = students_raw.loc[:,:'gender_sr']\n",
    "students[st_rel] = students_raw[st_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ef5324c58b5abae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T14:57:59.467181Z",
     "start_time": "2025-04-11T14:57:59.449450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create keyfile with student IDs\n",
    "keyfile_sid = dict(zip(students['ID'].astype(str), students['sID'].astype(str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1c61994463114",
   "metadata": {},
   "source": [
    "### Teacher data\n",
    "\n",
    "We received wide-format SPSS (.sav) files containing data for teachers. Of all survey data, only IOP and STRS scores are applicable to our research question. STRS variables seem easy to find. IOP variables are present in raw format and **not** named according to the codebook. -- MC, 11-04-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557280e900d082e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T12:26:20.012340Z",
     "start_time": "2025-04-17T12:26:19.937067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load SPSS files\n",
    "folder = '/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/Teacher Questionnaire Processing/Raw 2021-2022'\n",
    "\n",
    "file_path = glob.glob(folder + '/*.sav')  # SPSS files\n",
    "\n",
    "# This loads all the tq files in one mega-dataframe\n",
    "teachers_raw = [pd.read_spss(file) for file in file_path]\n",
    "\n",
    "# Check number of files loaded -> N = 75\n",
    "# len(teachers_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce773079ab7fe47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T12:26:24.872874Z",
     "start_time": "2025-04-17T12:26:24.840655Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Check df in long format\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m temp \u001B[38;5;241m=\u001B[39m teachers_raw[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmelt()\n\u001B[1;32m      3\u001B[0m temp\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Check df in long format\n",
    "temp = teachers_raw[0].melt()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b7f6ee90f0a932bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T18:55:31.381969Z",
     "start_time": "2025-04-11T18:55:30.716572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "folder = '/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/Teacher Questionnaire Processing/Raw_t1'\n",
    "\n",
    "file_path = glob.glob(folder + '/*.csv')\n",
    "\n",
    "dataframes = [pd.read_csv(file, sep=',') for file in file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c0c884f11bc3f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration__in_seconds_</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>...</th>\n",
       "      <th>T_MSSP28</th>\n",
       "      <th>T_COV1</th>\n",
       "      <th>T_COV2</th>\n",
       "      <th>T_COV3</th>\n",
       "      <th>T_COV3_remarks</th>\n",
       "      <th>T_COV4</th>\n",
       "      <th>T_COV4_remarks</th>\n",
       "      <th>T_general_remarks</th>\n",
       "      <th>Num</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-24 05:11:32</td>\n",
       "      <td>2022-05-24 05:32:44</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1271</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-24 05:32:44</td>\n",
       "      <td>R_22zxZ1hKBSNiYMM</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>NL</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Deze regels zijn er niet meer</td>\n",
       "      <td>Ook deze regels zijn er niet meer</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ik ben erg benieuwd naar de uitslag van zowel ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate              EndDate  Status  Progress  \\\n",
       "0  2022-05-24 05:11:32  2022-05-24 05:32:44       0       100   \n",
       "\n",
       "   Duration__in_seconds_  Finished         RecordedDate         ResponseId  \\\n",
       "0                   1271         1  2022-05-24 05:32:44  R_22zxZ1hKBSNiYMM   \n",
       "\n",
       "  DistributionChannel UserLanguage  ...  T_MSSP28  \\\n",
       "0           anonymous           NL  ...         4   \n",
       "\n",
       "                          T_COV1                             T_COV2  T_COV3  \\\n",
       "0  Deze regels zijn er niet meer  Ook deze regels zijn er niet meer       5   \n",
       "\n",
       "   T_COV3_remarks  T_COV4  T_COV4_remarks  \\\n",
       "0             NaN       5             NaN   \n",
       "\n",
       "                                   T_general_remarks  Num  Time  \n",
       "0  Ik ben erg benieuwd naar de uitslag van zowel ...    1     2  \n",
       "\n",
       "[1 rows x 354 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe to check\n",
    "# dataframes[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd649307c728cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes a long time to batch import all the .sav files into dataframes, so first check which files we need\n",
    "#todo second though, rewrite this if needed because this also takes a long time\n",
    "\n",
    "files_to_import = []\n",
    "\n",
    "for file in file_path:\n",
    "    try:\n",
    "        dataframe = pd.read_spss(file)\n",
    "        if any(re.match(r'^x\\d+_Q70_\\d+$', col) for col in dataframe.columns):  # Contains IOP columns\n",
    "            files_to_import.append(file)\n",
    "            print(f\"Found file: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a82c41658fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in block above inspired by this\n",
    "# files_to_import = []\n",
    "# \n",
    "# for file in file_path:\n",
    "#     try:\n",
    "#         dataframe = pd.read_spss(file)\n",
    "#         if any(re.match(r'^x\\d+_Q70_\\d+$', col) for col in dataframe.columns):  # Contains IOP columns\n",
    "#             files_to_import.append(file)\n",
    "#             print(f\"Found file: {file}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0023bf07712f1f",
   "metadata": {},
   "source": [
    "Below is the first attempt to limit teacher response dataframes and it failed gloriously.--MC, 11-04-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41852af956f6f951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:38:04.361633Z",
     "start_time": "2025-04-11T13:38:04.344840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually determined teacher ID variables\n",
    "id_cols_list = [\n",
    "    'ResponseId', \n",
    "    'SchoolID', \n",
    "    'classID', \n",
    "    'teacherID', \n",
    "    'gender', \n",
    "    'age', \n",
    "    'teaching_week', \n",
    "    'same_group', \n",
    "    'changes_group'\n",
    "]\n",
    "\n",
    "# Separate and format IOP and STRS columns\n",
    "iop_cols = [col for col in temp.columns if col.lower().startswith('iop')]  #TODO remove this bc it's probably not named like this\n",
    "strs_cols = [col for col in temp.columns if col.lower().startswith('strs')]\n",
    "# id_cols = [col for col in temp.columns if col.isin(id_cols_list)]\n",
    "id_cols = [col for col in temp.columns if col.lower() in [x.lower() for x in id_cols_list]]\n",
    "\n",
    "all_cols = id_cols + strs_cols + iop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "abb9c950f4f8d44c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:41:28.791608Z",
     "start_time": "2025-04-11T13:41:28.777268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration__in_seconds_</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>...</th>\n",
       "      <th>Q65</th>\n",
       "      <th>Q66</th>\n",
       "      <th>Q67</th>\n",
       "      <th>Q46</th>\n",
       "      <th>Q47</th>\n",
       "      <th>Q53</th>\n",
       "      <th>Q54</th>\n",
       "      <th>Q55</th>\n",
       "      <th>Q56</th>\n",
       "      <th>Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-17 01:11:41</td>\n",
       "      <td>2021-11-17 09:02:51</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28269.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-11-24 09:02:51</td>\n",
       "      <td>R_2rMjIqzzgeNrKGp</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>NL</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-24 09:13:09</td>\n",
       "      <td>2021-11-24 09:14:33</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>29.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-01 09:14:36</td>\n",
       "      <td>R_R8gwVUAlrPmpkM9</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>NL</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-09 08:36:14</td>\n",
       "      <td>2021-12-10 09:24:58</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89324.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-12-10 09:24:59</td>\n",
       "      <td>R_3NPUyPlcAxijh3I</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>NL</td>\n",
       "      <td>...</td>\n",
       "      <td>We zetten de kinderen met storend gedrag t.o.v...</td>\n",
       "      <td>Kinderen die extra aandacht nodig hebben vanwe...</td>\n",
       "      <td>Al wel beschreven, maar ook didactisch. Soms j...</td>\n",
       "      <td>Geen afstandsregels regels voor kinderen uit e...</td>\n",
       "      <td>Geen andere regels dan normaal. Geen afstand h...</td>\n",
       "      <td>Oneens</td>\n",
       "      <td>Mondkapjes in de gang: kinderen zitten de hele...</td>\n",
       "      <td>Nauwelijks</td>\n",
       "      <td>Mondkapje in de gangen wordt amper gedragen, o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 847 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            StartDate             EndDate      Status  Progress  \\\n",
       "0 2021-11-17 01:11:41 2021-11-17 09:02:51  IP Address      44.0   \n",
       "1 2021-11-24 09:13:09 2021-11-24 09:14:33  IP Address      29.0   \n",
       "2 2021-12-09 08:36:14 2021-12-10 09:24:58  IP Address     100.0   \n",
       "\n",
       "   Duration__in_seconds_ Finished        RecordedDate         ResponseId  \\\n",
       "0                28269.0    False 2021-11-24 09:02:51  R_2rMjIqzzgeNrKGp   \n",
       "1                   84.0    False 2021-12-01 09:14:36  R_R8gwVUAlrPmpkM9   \n",
       "2                89324.0     True 2021-12-10 09:24:59  R_3NPUyPlcAxijh3I   \n",
       "\n",
       "  DistributionChannel UserLanguage  ...  \\\n",
       "0           anonymous           NL  ...   \n",
       "1           anonymous           NL  ...   \n",
       "2           anonymous           NL  ...   \n",
       "\n",
       "                                                 Q65  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  We zetten de kinderen met storend gedrag t.o.v...   \n",
       "\n",
       "                                                 Q66  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Kinderen die extra aandacht nodig hebben vanwe...   \n",
       "\n",
       "                                                 Q67  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Al wel beschreven, maar ook didactisch. Soms j...   \n",
       "\n",
       "                                                 Q46  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Geen afstandsregels regels voor kinderen uit e...   \n",
       "\n",
       "                                                 Q47     Q53  \\\n",
       "0                                                        NaN   \n",
       "1                                                        NaN   \n",
       "2  Geen andere regels dan normaal. Geen afstand h...  Oneens   \n",
       "\n",
       "                                                 Q54         Q55  \\\n",
       "0                                                            NaN   \n",
       "1                                                            NaN   \n",
       "2  Mondkapjes in de gang: kinderen zitten de hele...  Nauwelijks   \n",
       "\n",
       "                                                 Q56 Num  \n",
       "0                                                      1  \n",
       "1                                                      1  \n",
       "2  Mondkapje in de gangen wordt amper gedragen, o...   1  \n",
       "\n",
       "[3 rows x 847 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp[all_cols].melt()  # Wide to long format\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8809599a634f88",
   "metadata": {},
   "source": [
    "## Translated R code\n",
    "We were provided R scripts to import and pre-process teacher survey responses. I can't read R code, so I took the 'rename_column_teacher_main.R' and asked Claude to convert it to Python.--MC, 11-04-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90493fa725f769ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# List files in the directory\n",
    "# In Jupyter, you may need to change this path to match your environment\n",
    "files = os.listdir('/Users/majaculjak/Desktop/RawTQ')\n",
    "\n",
    "# Check files that contain columns matching the pattern \"^x\\d+_Q70_\\d+$\"\n",
    "for file in files:\n",
    "    data = pd.read_spss(os.path.join('/Users/majaculjak/Desktop/RawTQ', file))\n",
    "    if any(re.match(r'^x\\d+_Q70_\\d+$', col) for col in data.columns):\n",
    "        print(file)\n",
    "\n",
    "# Processing a specific file (in R this was done manually by changing file index)\n",
    "# Select a file for processing\n",
    "file = files[0]  # You would change this index manually to process different files\n",
    "data = pd.read_spss(os.path.join('/Users/majaculjak/Desktop/RawTQ', file))\n",
    "\n",
    "# Function to get variable label (mimics attr(data[[col]], \"label\") in R)\n",
    "def get_label(data, column):\n",
    "    try:\n",
    "        return data[column].attrs['label']\n",
    "    except (KeyError, AttributeError):\n",
    "        return \"\"\n",
    "\n",
    "# Rename columns based on patterns\n",
    "new_column_names = {}\n",
    "\n",
    "for col in data.columns:\n",
    "    # CPCQ pattern\n",
    "    if 'CPCQ' in col:\n",
    "        cpcq_item = col.split('_')[0]\n",
    "        new_column_names[col] = f'T_{cpcq_item}'\n",
    "    \n",
    "    # MSSP pattern\n",
    "    elif 'MSSP' in col:\n",
    "        mssp_item = col.split('_')[0]\n",
    "        new_column_names[col] = f'T_{mssp_item}'\n",
    "    \n",
    "    # STRS pattern\n",
    "    elif 'STRS' in col:\n",
    "        strs_item = col.split('_')[0]\n",
    "        new_column_names[col] = f'T_{strs_item}'\n",
    "    \n",
    "    # expct pattern\n",
    "    elif 'expct' in col:\n",
    "        label = get_label(data, col)\n",
    "        child_exp = col.split('_')[2] if len(col.split('_')) > 2 else \"\"\n",
    "        \n",
    "        if 'Deze leerling behaalt waarschijnlijk een hoge score op de eindtoets in groep 8' in label:\n",
    "            new_column_names[col] = f'T_EXP1_{child_exp}'\n",
    "        elif 'officiele normeringen' in label:\n",
    "            new_column_names[col] = f'T_EXP1a_{child_exp}'\n",
    "        elif 'voor zijn/haar doen' in label:\n",
    "            new_column_names[col] = f'T_EXP1b_{child_exp}'\n",
    "        elif 'werkhouding' in label:\n",
    "            new_column_names[col] = f'T_EXP2_{child_exp}'\n",
    "    \n",
    "    # ID columns\n",
    "    elif 'SchoolID' in col:\n",
    "        new_column_names[col] = 'School_ID'\n",
    "    elif 'classID' in col:\n",
    "        new_column_names[col] = 'Class_ID'\n",
    "    elif 'teacherID' in col:\n",
    "        new_column_names[col] = 'Teacher_ID'\n",
    "    \n",
    "    # Print columns with Q for inspection\n",
    "    elif 'Q' in col:\n",
    "        print(col)\n",
    "        print(get_label(data, col))\n",
    "\n",
    "# Rename Covid questions\n",
    "for col in data.columns:\n",
    "    label = get_label(data, col)\n",
    "    \n",
    "    if 'bent u het eens met de huidige regels die gelden in de school' in label:\n",
    "        new_column_names[col] = 'T_COV3'\n",
    "    elif 'toelichting' in label:\n",
    "        if 'Q57' in col:\n",
    "            new_column_names[col] = 'T_COV3_remarks'\n",
    "        elif 'Q54' in col:\n",
    "            new_column_names[col] = 'T_COV3_remarks'\n",
    "        elif 'Q56' in col:\n",
    "            new_column_names[col] = 'T_COV4_remarks'\n",
    "        elif 'Q55' in col:\n",
    "            new_column_names[col] = 'T_COV4_remarks'\n",
    "    elif 'om de regels toe te passen in uw klas' in label:\n",
    "        new_column_names[col] = 'T_COV4'\n",
    "    elif 'Tot slot' in label:\n",
    "        new_column_names[col] = 'T_general_remarks'\n",
    "\n",
    "# Rename teacher considerations seating\n",
    "for col in data.columns:\n",
    "    if 'Q62' in col:\n",
    "        new_column_names[col] = 'TCSA1'\n",
    "    elif 'Q64' in col:\n",
    "        new_column_names[col] = 'TCSA2'\n",
    "    elif 'Q65' in col:\n",
    "        new_column_names[col] = 'TCSA3'\n",
    "    elif 'Q66' in col:\n",
    "        new_column_names[col] = 'TCSA4'\n",
    "    elif 'Q67' in col:\n",
    "        new_column_names[col] = 'TCSA5'\n",
    "\n",
    "# Process IOP questions\n",
    "# Note: You would need to define keyfile here or load it from somewhere\n",
    "# keyfile = pd.read_csv(\"path_to_keyfile.csv\")  # Adjust according to your keyfile location\n",
    "\n",
    "# This is placeholder code - you need to adjust based on your keyfile structure\n",
    "keyfile = pd.DataFrame({\n",
    "    'id': [],\n",
    "    'name': []\n",
    "})\n",
    "\n",
    "for i, col in enumerate(data.columns):\n",
    "    # Process Q68_X type columns (IOP)\n",
    "    match = re.match(r'^Q68_(\\d+)$', col)\n",
    "    if match:\n",
    "        child_number = match.group(1)\n",
    "        label = get_label(data, col)\n",
    "        child_name = re.sub(r'[^a-zA-Z0-9]', '', re.sub(r'.*\\- ', '', label))\n",
    "        \n",
    "        if not keyfile.empty:  # Only proceed if keyfile has data\n",
    "            matching_ids = keyfile.loc[keyfile['name'] == child_name, 'id']\n",
    "            if not matching_ids.empty:\n",
    "                child_id = matching_ids.iloc[0]\n",
    "                new_column_names[col] = f\"IOP_c{child_id}\"\n",
    "    \n",
    "    # Process x1_Q70_X type columns (IOP_more)\n",
    "    match = re.match(r'^x(\\d+)_Q70_(\\d+)$', col)\n",
    "    if match:\n",
    "        child_number = match.group(1)\n",
    "        item_number = int(match.group(2))\n",
    "        \n",
    "        label = get_label(data, col)\n",
    "        child_name = re.sub(r'[^a-zA-Z0-9]', '', re.sub(r'.*- (.*?) -.*', r'\\1', label))\n",
    "        \n",
    "        if not keyfile.empty:  # Only proceed if keyfile has data\n",
    "            matching_ids = keyfile.loc[keyfile['name'] == child_name, 'id']\n",
    "            if not matching_ids.empty:\n",
    "                child_id = matching_ids.iloc[0]\n",
    "                if item_number == 11:\n",
    "                    new_column_names[col] = f\"IOP_more_Rother1_c{child_id}\"\n",
    "                else:\n",
    "                    new_column_names[col] = f\"IOP_more_R{item_number}_c{child_id}\"\n",
    "    \n",
    "    # Process xX_Q70_11_TEXT type columns\n",
    "    match = re.match(r'^x(\\d+)_Q70_11_TEXT$', col)\n",
    "    if match:\n",
    "        child_number = match.group(1)\n",
    "        \n",
    "        label = get_label(data, col)\n",
    "        child_name = re.sub(r'[^a-zA-Z0-9]', '', re.sub(r'.*- (.*?) -.*', r'\\1', label))\n",
    "        \n",
    "        if not keyfile.empty:  # Only proceed if keyfile has data\n",
    "            matching_ids = keyfile.loc[keyfile['name'] == child_name, 'id']\n",
    "            if not matching_ids.empty:\n",
    "                child_id = matching_ids.iloc[0]\n",
    "                new_column_names[col] = f\"IOP_more_Rother2_c{child_id}\"\n",
    "    \n",
    "    # Process x1_Q71_X type columns (IOP_less)\n",
    "    match = re.match(r'^x(\\d+)_Q71_(\\d+)$', col)\n",
    "    if match:\n",
    "        child_number = match.group(1)\n",
    "        item_number = int(match.group(2))\n",
    "        \n",
    "        label = get_label(data, col)\n",
    "        child_name = re.sub(r'[^a-zA-Z0-9]', '', re.sub(r'.*- (.*?) -.*', r'\\1', label))\n",
    "        \n",
    "        if not keyfile.empty:  # Only proceed if keyfile has data\n",
    "            matching_ids = keyfile.loc[keyfile['name'] == child_name, 'id']\n",
    "            if not matching_ids.empty:\n",
    "                child_id = matching_ids.iloc[0]\n",
    "                if item_number == 8:\n",
    "                    new_column_names[col] = f\"IOP_less_Rother1_c{child_id}\"\n",
    "                else:\n",
    "                    new_column_names[col] = f\"IOP_less_R{item_number}_c{child_id}\"\n",
    "    \n",
    "    # Process xX_Q71_8_TEXT type columns\n",
    "    match = re.match(r'^x(\\d+)_Q71_8_TEXT$', col)\n",
    "    if match:\n",
    "        child_number = match.group(1)\n",
    "        \n",
    "        label = get_label(data, col)\n",
    "        child_name = re.sub(r'[^a-zA-Z0-9]', '', re.sub(r'.*- (.*?) -.*', r'\\1', label))\n",
    "        \n",
    "        if not keyfile.empty:  # Only proceed if keyfile has data\n",
    "            matching_ids = keyfile.loc[keyfile['name'] == child_name, 'id']\n",
    "            if not matching_ids.empty:\n",
    "                child_id = matching_ids.iloc[0]\n",
    "                new_column_names[col] = f\"IOP_less_Rother2_c{child_id}\"\n",
    "\n",
    "# Rename columns using the mappings\n",
    "data = data.rename(columns=new_column_names)\n",
    "\n",
    "# Remove columns matching pattern Q60_[123]\n",
    "columns_to_keep = [col for col in data.columns if not re.match(r'.*Q60_[123]', col)]\n",
    "data = data[columns_to_keep]\n",
    "\n",
    "# Save file\n",
    "file_name = file.split('.')[0]\n",
    "output_dir = Path('Raw_t1')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "data.to_csv(output_dir / f\"{file_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda069193184d8c",
   "metadata": {},
   "source": [
    "## Translated R code (optimized)\n",
    "Then I asked Claude to optimize the code. -- Maja, 11-04-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "100738ef9f4e9adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T14:58:48.039365Z",
     "start_time": "2025-04-11T14:58:48.034664Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2264988dbc0e53d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T14:58:48.099062Z",
     "start_time": "2025-04-11T14:58:48.092394Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(data, column):\n",
    "    \"\"\"Get the label attribute of a column if it exists.\"\"\"\n",
    "    try:\n",
    "        return data[column].attrs['label']\n",
    "    except (KeyError, AttributeError):\n",
    "        return \"\"\n",
    "\n",
    "def extract_child_id(label):\n",
    "    \"\"\"\n",
    "    Extract child ID from label text as a string.\n",
    "    Attempts to find the first numeric ID in the label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract the first sequence of digits from the label\n",
    "        digits_match = re.search(r'(\\d+)', str(label))\n",
    "        if digits_match:\n",
    "            return str(digits_match.group(1))\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0c067d25506e84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T14:58:48.139085Z",
     "start_time": "2025-04-11T14:58:48.123717Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_teacher_questionnaire(data_dir, output_dir, keyfile_sid=None):\n",
    "    \"\"\"\n",
    "    Process teacher questionnaire data files by renaming columns according to specific patterns.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing SPSS data files\n",
    "        output_dir: Directory where processed CSV files will be saved\n",
    "        keyfile_sid: Dictionary mapping student IDs to sIDs\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # List files in the directory\n",
    "    files = os.listdir(data_dir)\n",
    "    \n",
    "    # Find files with x#_Q70_# pattern\n",
    "    q70_files = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            data = pd.read_spss(os.path.join(data_dir, file))\n",
    "            if any(re.match(r'^x\\d+_Q70_\\d+$', col) for col in data.columns):\n",
    "                q70_files.append(file)\n",
    "                print(f\"Found Q70 pattern in file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    # Process each file\n",
    "    for file in files:\n",
    "        try:\n",
    "            print(f\"Processing {file}...\")\n",
    "            data = pd.read_spss(os.path.join(data_dir, file))\n",
    "            \n",
    "            # Dictionary to store column renamings\n",
    "            rename_map = {}\n",
    "            \n",
    "            # Process columns by pattern\n",
    "            for col in data.columns:\n",
    "                # Get column label\n",
    "                label = get_label(data, col)\n",
    "                \n",
    "                # Process by pattern\n",
    "                if 'CPCQ' in col or 'MSSP' in col or 'STRS' in col:\n",
    "                    # Standard questionnaire items\n",
    "                    prefix = col.split('_')[0]\n",
    "                    rename_map[col] = f'T_{prefix}'\n",
    "                \n",
    "                # Handle expct pattern\n",
    "                elif 'expct' in col:\n",
    "                    parts = col.split('_')\n",
    "                    if len(parts) > 2:\n",
    "                        child_exp = parts[2]\n",
    "                        if 'Deze leerling behaalt waarschijnlijk een hoge score op de eindtoets in groep 8' in label:\n",
    "                            rename_map[col] = f'T_EXP1_{child_exp}'\n",
    "                        elif 'officiele normeringen' in label:\n",
    "                            rename_map[col] = f'T_EXP1a_{child_exp}'\n",
    "                        elif 'voor zijn/haar doen' in label:\n",
    "                            rename_map[col] = f'T_EXP1b_{child_exp}'\n",
    "                        elif 'werkhouding' in label:\n",
    "                            rename_map[col] = f'T_EXP2_{child_exp}'\n",
    "                \n",
    "                # Handle ID columns\n",
    "                elif col == 'SchoolID':\n",
    "                    rename_map[col] = 'School_ID'\n",
    "                elif col == 'classID':\n",
    "                    rename_map[col] = 'Class_ID'\n",
    "                elif col == 'teacherID':\n",
    "                    rename_map[col] = 'Teacher_ID'\n",
    "                \n",
    "                # Handle Covid questions\n",
    "                elif 'bent u het eens met de huidige regels die gelden in de school' in label:\n",
    "                    rename_map[col] = 'T_COV3'\n",
    "                elif 'toelichting' in label and ('Q57' in col or 'Q54' in col):\n",
    "                    rename_map[col] = 'T_COV3_remarks'\n",
    "                elif 'toelichting' in label and ('Q56' in col or 'Q55' in col):\n",
    "                    rename_map[col] = 'T_COV4_remarks'\n",
    "                elif 'om de regels toe te passen in uw klas' in label:\n",
    "                    rename_map[col] = 'T_COV4'\n",
    "                elif 'Tot slot' in label:\n",
    "                    rename_map[col] = 'T_general_remarks'\n",
    "                \n",
    "                # Handle teacher considerations seating\n",
    "                elif col.startswith('Q6'):\n",
    "                    q_num = col.split('_')[0]\n",
    "                    if q_num == 'Q62':\n",
    "                        rename_map[col] = 'TCSA1'\n",
    "                    elif q_num == 'Q64':\n",
    "                        rename_map[col] = 'TCSA2'\n",
    "                    elif q_num == 'Q65':\n",
    "                        rename_map[col] = 'TCSA3'\n",
    "                    elif q_num == 'Q66':\n",
    "                        rename_map[col] = 'TCSA4'\n",
    "                    elif q_num == 'Q67':\n",
    "                        rename_map[col] = 'TCSA5'\n",
    "            \n",
    "            # Process IOP questions if keyfile is available\n",
    "            if keyfile_sid:\n",
    "                for col in data.columns:\n",
    "                    # IOP base questions (Q68_X)\n",
    "                    match = re.match(r'^Q68_(\\d+)$', col)\n",
    "                    if match:\n",
    "                        child_id = extract_child_id(get_label(data, col))\n",
    "                        if child_id in keyfile_sid:\n",
    "                            sid = keyfile_sid[child_id]\n",
    "                            rename_map[col] = f\"IOP_c{sid}\"\n",
    "                    \n",
    "                    # IOP more questions (x#_Q70_X)\n",
    "                    match = re.match(r'^x(\\d+)_Q70_(\\d+)$', col)\n",
    "                    if match:\n",
    "                        item_number = int(match.group(2))\n",
    "                        child_id = extract_child_id(get_label(data, col))\n",
    "                        if child_id in keyfile_sid:\n",
    "                            sid = keyfile_sid[child_id]\n",
    "                            suffix = f\"Rother1_c{sid}\" if item_number == 11 else f\"R{item_number}_c{sid}\"\n",
    "                            rename_map[col] = f\"IOP_more_{suffix}\"\n",
    "                    \n",
    "                    # IOP more other text (x#_Q70_11_TEXT)\n",
    "                    match = re.match(r'^x(\\d+)_Q70_11_TEXT$', col)\n",
    "                    if match:\n",
    "                        child_id = extract_child_id(get_label(data, col))\n",
    "                        if child_id in keyfile_sid:\n",
    "                            sid = keyfile_sid[child_id]\n",
    "                            rename_map[col] = f\"IOP_more_Rother2_c{sid}\"\n",
    "                    \n",
    "                    # IOP less questions (x#_Q71_X)\n",
    "                    match = re.match(r'^x(\\d+)_Q71_(\\d+)$', col)\n",
    "                    if match:\n",
    "                        item_number = int(match.group(2))\n",
    "                        child_id = extract_child_id(get_label(data, col))\n",
    "                        if child_id in keyfile_sid:\n",
    "                            sid = keyfile_sid[child_id]\n",
    "                            suffix = f\"Rother1_c{sid}\" if item_number == 8 else f\"R{item_number}_c{sid}\"\n",
    "                            rename_map[col] = f\"IOP_less_{suffix}\"\n",
    "                    \n",
    "                    # IOP less other text (x#_Q71_8_TEXT)\n",
    "                    match = re.match(r'^x(\\d+)_Q71_8_TEXT$', col)\n",
    "                    if match:\n",
    "                        child_id = extract_child_id(get_label(data, col))\n",
    "                        if child_id in keyfile_sid:\n",
    "                            sid = keyfile_sid[child_id]\n",
    "                            rename_map[col] = f\"IOP_less_Rother2_c{sid}\"\n",
    "            \n",
    "            # Rename columns\n",
    "            data = data.rename(columns=rename_map)\n",
    "            \n",
    "            # Remove columns matching pattern Q60_[123]\n",
    "            data = data[[col for col in data.columns if not re.match(r'.*Q60_[123]', col)]]\n",
    "            \n",
    "            # Save file\n",
    "            file_name = file.split('.')[0]\n",
    "            data.to_csv(os.path.join(output_dir, f\"{file_name}.csv\"), index=False)\n",
    "            print(f\"Saved {file_name}.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11aee4cdd11ecb95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:00:32.951023Z",
     "start_time": "2025-04-11T15:00:29.429900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tq1_10_64.sav...\n",
      "Saved tq1_10_64.csv\n",
      "Processing tq1_10_65.sav...\n",
      "Saved tq1_10_65.csv\n"
     ]
    }
   ],
   "source": [
    "# Set your directory paths\n",
    "data_dir = '/Users/majaculjak/Desktop/RawTQ'  # Change this to your input directory\n",
    "output_dir = '/Users/majaculjak/Desktop/ProcessedTQ'  # Change this to your output directory\n",
    "\n",
    "# Load or create your keyfile dictionary\n",
    "# Option 1: Load students data and create ID to sID mapping\n",
    "# students = pd.read_csv('path_to_your_students_data.csv')  # Change to your actual path\n",
    "# keyfile_sid = dict(zip(students['ID'], students['sID']))\n",
    "\n",
    "# Option 2: For testing with a small dictionary\n",
    "# keyfile_sid = {'123': 'S123', '456': 'S456'}  # Example mapping\n",
    "\n",
    "# Process the files\n",
    "process_teacher_questionnaire(data_dir, output_dir, keyfile_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64ee4e56bdc6cae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T14:58:50.375640Z",
     "start_time": "2025-04-11T14:58:50.373645Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp = pd.read_csv('/Volumes/WRKGRP/STD-FSW-BSI-SD-Movement_Tracking/Teacher Questionnaire Processing/Raw_t1/tq1_32_75.csv')\n",
    "# temp.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d86b3139d4d822bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:01:24.593409Z",
     "start_time": "2025-04-11T15:01:23.482958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StartDate</td>\n",
       "      <td>2021-11-17 03:05:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EndDate</td>\n",
       "      <td>2021-11-18 00:02:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Status</td>\n",
       "      <td>IP Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Progress</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duration__in_seconds_</td>\n",
       "      <td>75418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>Q53</td>\n",
       "      <td>Heel erg eens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159</th>\n",
       "      <td>Q54</td>\n",
       "      <td>Wij zijn een school die redelijk nuchter met d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>Q55</td>\n",
       "      <td>Volledig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>Q56</td>\n",
       "      <td>Omdat er nu niet echt scherpe maatregelen zijn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>Num</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   variable                                              value\n",
       "0                 StartDate                                2021-11-17 03:05:41\n",
       "1                   EndDate                                2021-11-18 00:02:39\n",
       "2                    Status                                         IP Address\n",
       "3                  Progress                                              100.0\n",
       "4     Duration__in_seconds_                                            75418.0\n",
       "...                     ...                                                ...\n",
       "6158                    Q53                                      Heel erg eens\n",
       "6159                    Q54  Wij zijn een school die redelijk nuchter met d...\n",
       "6160                    Q55                                           Volledig\n",
       "6161                    Q56    Omdat er nu niet echt scherpe maatregelen zijn.\n",
       "6162                    Num                                                  1\n",
       "\n",
       "[6163 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('/Users/majaculjak/Desktop/ProcessedTQ/tq1_10_64.csv')\n",
    "temp.melt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
